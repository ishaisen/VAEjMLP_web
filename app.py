# =====================================================
# app.py (FULL REPLACEABLE VERSION)
# VAEjMLP latent-SHAP + ç¨³å®šæ€§ + SHAPå¯è§†åŒ– + GO/KEGG(æŒ‰é’®åˆ‡æ¢+æ°”æ³¡å›¾)
# + DE(å«ç®±çº¿å›¾) + èšç±» + ç”Ÿå­˜
#
# UI:
#   - Demo gateï¼ˆæœªå¼€å¯æ—¶ä»…æ˜¾ç¤ºå¼€å…³ï¼‰
#   - Hero: Input / Workflow / Output
#   - é¡¶éƒ¨ Sticky Toolbarï¼ˆé”šç‚¹è·³è½¬+å›åˆ°é¡¶éƒ¨+æ¨¡å—é«˜äº®ï¼‰
#   - æ¨¡å—å¯¼èˆªï¼šæŒ‰é’®ï¼ˆæ›¿ä»£ Tabsï¼‰
#   - ä¸‹è½½ä¸­å¿ƒï¼šæ–‡ä»¶åˆ—è¡¨ + å•æ–‡ä»¶ä¸‹è½½ + ZIP + REPORT.mdï¼ˆä¸ä¾èµ– tabulateï¼‰
#   - æ¸…é™¤ç¼“å­˜ï¼šä¸€é”®æ¸…ç©ºè¿è¡Œç»“æœä¸ä¸‹è½½ç¼“å­˜
#
# CHANGE:
#   - é€‰ä¸­æ¨¡å—æŒ‰é’®ï¼ˆâ€œTabsâ€æ›¿ä»£æŒ‰é’®ï¼‰é¢œè‰²æ›´æ˜æ˜¾
#   - ä¸ä½¿ç”¨å¯¹å· âœ…ï¼ˆé€‰ä¸­æ€ä¸æ˜¾ç¤ºä»»ä½•å¯¹å·/æ ‡è®°ï¼‰
# =====================================================

import os
import io
import zipfile
from datetime import datetime

import streamlit as st
import streamlit.components.v1 as components

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
from sklearn.cluster import KMeans

import shap
import matplotlib.pyplot as plt

# ----------------- Optional deps -----------------
try:
    from scipy.stats import ttest_ind
    SCIPY_OK = True
except Exception:
    SCIPY_OK = False

try:
    from statsmodels.stats.multitest import multipletests
    STATSMODELS_OK = True
except Exception:
    STATSMODELS_OK = False

try:
    import gseapy as gp
    GSEAPY_OK = True
except Exception:
    GSEAPY_OK = False

try:
    from lifelines import CoxPHFitter, KaplanMeierFitter
    from lifelines.statistics import logrank_test
    from lifelines.utils import concordance_index
    LIFELINES_OK = True
except Exception:
    LIFELINES_OK = False


# =====================================================
# Demo files (HIDDEN)
# =====================================================
DEMO_DIR = "."
DEMO_RNA = "TCGA_GTEX_tmp.csv"
DEMO_LAB = "labels.csv"
DEMO_SUR = "sur.csv"


# =====================================================
# Utils
# =====================================================
def now_stamp():
    return datetime.now().strftime("%Y-%m-%d_%H%M%S")


def set_seed(seed: int):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


@st.cache_data(show_spinner=False)
def read_csv_cached(uploaded_file) -> pd.DataFrame:
    return pd.read_csv(uploaded_file)


@st.cache_data(show_spinner=False)
def read_csv_path_cached(path: str) -> pd.DataFrame:
    return pd.read_csv(path)


def to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8")


def fig_to_png_bytes(fig) -> bytes:
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=200, bbox_inches="tight")
    buf.seek(0)
    return buf.read()


def safe_rename_index_col(df: pd.DataFrame) -> pd.DataFrame:
    if "Unnamed: 0" in df.columns:
        df = df.rename(columns={"Unnamed: 0": "Gene"}).set_index("Gene")
    return df


def _norm(s: str) -> str:
    return str(s).strip().lower().replace(" ", "").replace("-", "").replace("_", "")


def clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).replace("\ufeff", "").strip() for c in df.columns]
    return df


def normalize_labels_df(labels_raw: pd.DataFrame):
    labels = clean_columns(labels_raw.copy())
    if labels.shape[1] < 2:
        raise ValueError("Label æ–‡ä»¶è‡³å°‘éœ€è¦ä¸¤åˆ—ï¼ˆæ ·æœ¬åˆ— + æ ‡ç­¾åˆ—ï¼‰ã€‚")

    col_map = {_norm(c): c for c in labels.columns}
    sample_alias = ["sample", "sampleid", "sample_id", "id", "patient", "patientid", "subject", "subjectid"]
    label_alias = ["label", "group", "class", "y", "target", "phenotype", "status", "casecontrol", "case_control"]

    sample_col = None
    label_col = None
    for a in sample_alias:
        if _norm(a) in col_map:
            sample_col = col_map[_norm(a)]
            break
    for a in label_alias:
        if _norm(a) in col_map:
            label_col = col_map[_norm(a)]
            break

    fallback_sample = labels.columns[0]
    fallback_label = labels.columns[1] if labels.columns[1] != fallback_sample else labels.columns[0]

    if sample_col is None:
        sample_col = fallback_sample
    if label_col is None:
        label_col = fallback_label

    detect_info = {
        "raw_columns": list(labels.columns),
        "detected_sample_col": sample_col,
        "detected_label_col": label_col,
    }

    labels = labels.rename(columns={sample_col: "Sample", label_col: "Label"})
    labels["Sample"] = labels["Sample"].astype(str).str.strip()
    return labels[["Sample", "Label"]], detect_info


def align_rna_labels(rna_raw: pd.DataFrame, labels_raw: pd.DataFrame):
    rna = safe_rename_index_col(rna_raw.copy())
    rna = clean_columns(rna)
    rna.columns = rna.columns.astype(str)

    labels, label_detect = normalize_labels_df(labels_raw)

    samples_rna = set(rna.columns.tolist())
    samples_lab = set(labels["Sample"].tolist())
    common = sorted(list(samples_rna.intersection(samples_lab)))

    if len(common) < 4:
        raise ValueError(f"RNA ä¸ Label äº¤é›†æ ·æœ¬æ•°å¤ªå°‘ï¼ˆ{len(common)}ï¼‰ï¼Œæ— æ³•è®­ç»ƒã€‚")

    align_info = {
        "rna_samples": len(samples_rna),
        "label_samples": len(samples_lab),
        "common_samples": len(common),
        "used_samples": len(common),
        "took_intersection": False,
    }

    if samples_rna != samples_lab:
        align_info["took_intersection"] = True
        rna = rna[common]
        labels = labels.set_index("Sample").loc[common].reset_index()

    labels = labels.set_index("Sample").loc[rna.columns].reset_index()
    labels = clean_columns(labels)

    return rna, labels, align_info, label_detect


def ensure_2d_shap(shap_values, features_2d: np.ndarray) -> np.ndarray:
    if isinstance(shap_values, list):
        shap_z = shap_values[0]
    else:
        shap_z = shap_values
    shap_z = np.array(shap_z)

    if shap_z.ndim == 3 and shap_z.shape[-1] == 1:
        shap_z = shap_z[:, :, 0]
    if shap_z.ndim == 3 and shap_z.shape[0] == 1:
        shap_z = shap_z[0]

    if shap_z.ndim != 2:
        raise ValueError(f"Unexpected SHAP shape: {shap_z.shape}")

    if shap_z.shape[0] != features_2d.shape[0] or shap_z.shape[1] != features_2d.shape[1]:
        raise ValueError(f"Shape mismatch: shap={shap_z.shape}, features={features_2d.shape}")

    return shap_z


def df_to_markdown_fallback(df: pd.DataFrame) -> str:
    df2 = df.copy().fillna("")
    cols = [str(c) for c in df2.columns.tolist()]
    header = "| " + " | ".join(cols) + " |"
    sep = "| " + " | ".join(["---"] * len(cols)) + " |"
    rows = []
    for _, r in df2.iterrows():
        rows.append("| " + " | ".join([str(x) for x in r.tolist()]) + " |")
    return "\n".join([header, sep] + rows)


# ---------------- DE ----------------
def compute_de_top_genes(rna: pd.DataFrame, labels: pd.DataFrame, top_genes: list):
    if not SCIPY_OK:
        raise RuntimeError("ç¼ºå°‘ scipyï¼Œæ— æ³•åš t-testã€‚è¯·å®‰è£…ï¼špip install scipy")
    if not STATSMODELS_OK:
        raise RuntimeError("ç¼ºå°‘ statsmodelsï¼Œæ— æ³•åš FDRã€‚è¯·å®‰è£…ï¼špip install statsmodels")

    rna = clean_columns(rna.copy())
    rna.columns = rna.columns.astype(str)

    lab = clean_columns(labels.copy())
    if ("Sample" not in lab.columns) or ("Label" not in lab.columns):
        lab, _ = normalize_labels_df(lab)
    else:
        lab["Sample"] = lab["Sample"].astype(str).str.strip()

    lab2 = lab.set_index("Sample").reindex(rna.columns)

    missing = lab2.index[lab2["Label"].isna()].tolist()
    if len(missing) > 0:
        raise ValueError(f"labels ä¸­ç¼ºå°‘ {len(missing)} ä¸ªæ ·æœ¬çš„æ ‡ç­¾ï¼ˆç¤ºä¾‹å‰5ä¸ªï¼‰ï¼š{missing[:5]}")

    groups = pd.Series(lab2["Label"].values).unique().tolist()
    if len(groups) != 2:
        raise ValueError(f"å·®å¼‚åˆ†æéœ€è¦ä¸¤ç»„ Labelï¼Œç›®å‰å‘ç° {len(groups)} ç»„ï¼š{groups}")

    g0, g1 = groups[0], groups[1]
    s0 = lab2[lab2["Label"] == g0].index.tolist()
    s1 = lab2[lab2["Label"] == g1].index.tolist()

    if len(s0) < 2 or len(s1) < 2:
        raise ValueError(f"ä¸¤ç»„æ ·æœ¬æ•°ä¸è¶³ï¼š{g0}={len(s0)}, {g1}={len(s1)}ï¼ˆæ¯ç»„è‡³å°‘ 2ï¼‰")

    eps = 1e-9
    rows = []
    for gene in top_genes:
        if gene not in rna.index:
            continue
        x0 = rna.loc[gene].reindex(s0).astype(float).values
        x1 = rna.loc[gene].reindex(s1).astype(float).values

        _, p = ttest_ind(x1, x0, equal_var=False, nan_policy="omit")
        m0 = np.nanmean(x0)
        m1 = np.nanmean(x1)
        log2fc = np.log2((m1 + eps) / (m0 + eps))
        rows.append([gene, m0, m1, log2fc, p])

    de = pd.DataFrame(rows, columns=["Gene", f"Mean({g0})", f"Mean({g1})", "log2FC", "p_value"])
    if len(de) == 0:
        raise ValueError("Top genes åœ¨ RNA ä¸­æœªåŒ¹é…åˆ°ä»»ä½•åŸºå› ã€‚")

    de["FDR"] = multipletests(de["p_value"].values, method="fdr_bh")[1]
    de = de.sort_values(["FDR", "p_value"], ascending=True).reset_index(drop=True)
    return de, (g0, g1)


def plot_gene_boxplots(rna: pd.DataFrame, labels: pd.DataFrame, genes: list, group_order=None):
    rna = clean_columns(rna.copy())
    rna.columns = rna.columns.astype(str)

    lab = clean_columns(labels.copy())
    if ("Sample" not in lab.columns) or ("Label" not in lab.columns):
        lab, _ = normalize_labels_df(lab)
    else:
        lab["Sample"] = lab["Sample"].astype(str).str.strip()

    lab2 = lab.set_index("Sample").reindex(rna.columns)
    if lab2["Label"].isna().any():
        missing = lab2.index[lab2["Label"].isna()].tolist()
        raise ValueError(f"labels ç¼ºå°‘ {len(missing)} ä¸ªæ ·æœ¬çš„ Labelï¼ˆç¤ºä¾‹å‰5ï¼‰ï¼š{missing[:5]}")

    groups = pd.Series(lab2["Label"].values).unique().tolist()
    if group_order is not None:
        groups = [g for g in group_order if g in groups]
    else:
        groups = sorted(groups, key=lambda x: str(x))

    genes_exist = [g for g in genes if g in rna.index]
    if len(genes_exist) == 0:
        raise ValueError("é€‰æ‹©çš„åŸºå› åœ¨ RNA é‡Œéƒ½æ‰¾ä¸åˆ°ã€‚")

    n = len(genes_exist)
    height = max(4.5, min(1.0 * n + 2.0, 18.0))
    fig = plt.figure(figsize=(9.5, height))

    for i, gene in enumerate(genes_exist, start=1):
        ax = plt.subplot(n, 1, i)
        data = []
        for g in groups:
            sids = lab2.index[lab2["Label"] == g].tolist()
            vals = rna.loc[gene].reindex(sids).astype(float).values
            data.append(vals)

        ax.boxplot(data, labels=[str(g) for g in groups], showfliers=False)
        ax.set_title(gene, fontsize=10, loc="left")
        ax.set_ylabel("Expr")
        ax.grid(True, axis="y", alpha=0.2)
        if i != n:
            ax.set_xlabel("")
        else:
            ax.set_xlabel("Label group")

    plt.tight_layout()
    return fig


# ---------------- Enrich ----------------
def run_enrichr(top_genes: list, organism: str = "Human"):
    if not GSEAPY_OK:
        raise RuntimeError("ç¼ºå°‘ gseapyï¼Œæ— æ³•åš GO/KEGGã€‚è¯·å®‰è£…ï¼špip install gseapy")

    if organism.lower().startswith("h"):
        libs = [
            "GO_Biological_Process_2021",
            "GO_Molecular_Function_2021",
            "GO_Cellular_Component_2021",
            "KEGG_2021_Human",
        ]
    else:
        libs = [
            "GO_Biological_Process_2021",
            "GO_Molecular_Function_2021",
            "GO_Cellular_Component_2021",
            "KEGG_2021_Mouse",
        ]

    out = {}
    for lib in libs:
        enr = gp.enrichr(gene_list=top_genes, gene_sets=lib, organism=organism, outdir=None)
        out[lib] = enr.results.copy()
    return out


def _pick_col(df: pd.DataFrame, candidates: list, default=None):
    cols = {c.lower(): c for c in df.columns}
    for cand in candidates:
        if cand.lower() in cols:
            return cols[cand.lower()]
    return default


def plot_enrich_bubble(df: pd.DataFrame, title: str, top_n: int = 20):
    if df is None or len(df) == 0:
        raise ValueError("å¯Œé›†ç»“æœä¸ºç©ºï¼Œæ— æ³•ç»˜å›¾ã€‚")

    term_col = _pick_col(df, ["Term", "term"], default=df.columns[0])
    adjp_col = _pick_col(df, ["Adjusted P-value", "Adjusted P-value "])
    p_col = _pick_col(df, ["P-value", "p_value", "p-value"])
    comb_col = _pick_col(df, ["Combined Score", "combined_score", "Combined Score "])

    d = df.copy()
    if adjp_col is not None:
        d = d.sort_values(adjp_col, ascending=True)
    elif p_col is not None:
        d = d.sort_values(p_col, ascending=True)

    d = d.head(int(top_n)).copy()
    d[term_col] = d[term_col].astype(str)

    eps = 1e-300
    if adjp_col is not None:
        d["_adjp"] = pd.to_numeric(d[adjp_col], errors="coerce").fillna(1.0)
    elif p_col is not None:
        d["_adjp"] = pd.to_numeric(d[p_col], errors="coerce").fillna(1.0)
    else:
        d["_adjp"] = 1.0

    d["_mlog10"] = -np.log10(d["_adjp"].values + eps)

    if comb_col is not None:
        d["_x"] = pd.to_numeric(d[comb_col], errors="coerce").fillna(d["_mlog10"])
        x_label = comb_col
    else:
        d["_x"] = d["_mlog10"]
        x_label = "-log10(p_adj)"

    y_labels = d[term_col].tolist()[::-1]
    x = d["_x"].values[::-1]
    size = (d["_mlog10"].values[::-1] + 1.0) ** 2 * 12
    color = d["_adjp"].values[::-1]

    fig = plt.figure(figsize=(9.5, max(4.2, 0.28 * len(y_labels) + 1.8)))
    ax = plt.gca()
    sc = ax.scatter(x, range(len(y_labels)), s=size, c=color)
    ax.set_yticks(range(len(y_labels)))
    ax.set_yticklabels(y_labels, fontsize=9)
    ax.set_xlabel(x_label)
    ax.set_title(title)
    ax.grid(True, axis="x", alpha=0.25)
    cbar = plt.colorbar(sc)
    cbar.set_label("Adjusted P-value (smaller = better)")
    plt.tight_layout()
    return fig


# ---------------- Cluster/Survival ----------------
def cluster_samples_by_top_genes(rna: pd.DataFrame, top_genes: list, n_clusters: int = 2, seed: int = 42):
    rna = clean_columns(rna.copy())
    rna.columns = rna.columns.astype(str)

    genes_exist = [g for g in top_genes if g in rna.index]
    if len(genes_exist) < 2:
        raise ValueError("Top genes åœ¨ RNA ä¸­åŒ¹é…åˆ°çš„åŸºå› å¤ªå°‘ï¼ˆ<2ï¼‰ï¼Œæ— æ³•èšç±»ã€‚")

    X = rna.loc[genes_exist].T.astype(float)  # samples x genes
    X_scaled = StandardScaler().fit_transform(X.values)

    km = KMeans(n_clusters=int(n_clusters), random_state=int(seed), n_init="auto")
    clusters = km.fit_predict(X_scaled)

    cluster_df = pd.DataFrame({"Sample": X.index.astype(str), "Cluster": clusters.astype(int)})
    X_scaled_df = pd.DataFrame(X_scaled, index=X.index.astype(str), columns=genes_exist)
    return cluster_df, X_scaled_df


def km_plot_by_group(surv_df: pd.DataFrame, group_col: str, time_col: str = "Time", event_col: str = "Event"):
    if not LIFELINES_OK:
        raise RuntimeError("ç¼ºå°‘ lifelinesï¼Œæ— æ³•åš KM/Coxã€‚è¯·å®‰è£…ï¼špip install lifelines")

    fig = plt.figure(figsize=(7.8, 4.6))
    kmf = KaplanMeierFitter()
    groups = sorted(surv_df[group_col].unique().tolist())

    for g in groups:
        dfg = surv_df[surv_df[group_col] == g]
        kmf.fit(durations=dfg[time_col], event_observed=dfg[event_col], label=f"{group_col}={g} (n={len(dfg)})")
        kmf.plot(ci_show=False)

    plt.title("Kaplan-Meier")
    plt.xlabel("Time")
    plt.ylabel("Survival probability")
    plt.tight_layout()

    p_lr = None
    if len(groups) == 2:
        g0, g1 = groups
        df0 = surv_df[surv_df[group_col] == g0]
        df1 = surv_df[surv_df[group_col] == g1]
        lr = logrank_test(
            df0[time_col], df1[time_col],
            event_observed_A=df0[event_col],
            event_observed_B=df1[event_col],
        )
        p_lr = float(lr.p_value)

    return fig, p_lr


# =====================================================
# Artifact manager (Downloads center)
# =====================================================
def artifacts_init():
    if "cache_artifacts" not in st.session_state:
        st.session_state["cache_artifacts"] = {}
    if "cache_fig_pngs" not in st.session_state:
        st.session_state["cache_fig_pngs"] = {}


def artifact_put_bytes(name: str, b: bytes, mime: str, kind: str = "file", note: str = ""):
    artifacts_init()
    st.session_state["cache_artifacts"][name] = {"bytes": b, "mime": mime, "kind": kind, "note": note}


def artifact_put_df_csv(name: str, df: pd.DataFrame, note: str = ""):
    artifact_put_bytes(name, to_csv_bytes(df), "text/csv", kind="csv", note=note)


def artifact_put_fig_png(name: str, fig, note: str = ""):
    b = fig_to_png_bytes(fig)
    artifact_put_bytes(name, b, "image/png", kind="png", note=note)
    st.session_state["cache_fig_pngs"][name] = b


def build_report_md() -> str:
    src = st.session_state.get("cache_data_source", "unknown")
    at = st.session_state.get("cache_cached_at", "")
    params = st.session_state.get("cache_params", {})
    top20 = st.session_state.get("cache_top20_genes", [])
    summary_df = st.session_state.get("cache_summary_df", None)

    md = []
    md.append("# VAEjMLP latent-SHAP Results Report\n\n")
    md.append(f"- Generated at: **{datetime.now().isoformat(timespec='seconds')}**\n")
    md.append(f"- Cached at: **{at}**\n")
    md.append(f"- Data source: **{src}**\n\n")

    md.append("## Parameters\n")
    if params:
        for k, v in params.items():
            md.append(f"- {k}: {v}\n")
    else:
        md.append("- (no params captured)\n")
    md.append("\n")

    md.append("## Metrics Summary (mean Â± std)\n")
    if isinstance(summary_df, pd.DataFrame):
        md.append(df_to_markdown_fallback(summary_df))
        md.append("\n\n")
    else:
        md.append("- (no summary)\n\n")

    md.append("## Top 20 Biomarkers\n")
    if top20:
        for g in top20:
            md.append(f"- {g}\n")
    else:
        md.append("- (no top20)\n")

    md.append("\n## Notes\n")
    md.append("- ZIP bundle includes CSV/PNG produced in current session.\n")
    md.append("- GO/KEGG requires gseapy and network access to Enrichr.\n")
    md.append("- DE requires scipy + statsmodels.\n")
    md.append("- Survival requires lifelines.\n")
    return "".join(md)


def build_results_zip(ts: str) -> bytes:
    artifacts_init()
    zbuf = io.BytesIO()
    with zipfile.ZipFile(zbuf, "w", zipfile.ZIP_DEFLATED) as zf:
        for name, meta in st.session_state["cache_artifacts"].items():
            zf.writestr(name, meta["bytes"])
        zf.writestr("REPORT.md", build_report_md().encode("utf-8"))
        meta = {
            "generated_at": datetime.now().isoformat(timespec="seconds"),
            "data_source": st.session_state.get("cache_data_source", "unknown"),
            "cached_at": st.session_state.get("cache_cached_at", ""),
            "bundle_ts": ts,
            "artifact_count": len(st.session_state["cache_artifacts"]),
        }
        zf.writestr("README_metadata.json", pd.Series(meta).to_json())
    zbuf.seek(0)
    return zbuf.read()


def artifact_table_df():
    artifacts_init()
    rows = []
    for name, meta in st.session_state["cache_artifacts"].items():
        size_kb = len(meta["bytes"]) / 1024.0
        rows.append([name, meta.get("kind", ""), meta.get("mime", ""), f"{size_kb:.1f} KB", meta.get("note", "")])
    if not rows:
        return pd.DataFrame(columns=["File", "Type", "MIME", "Size", "Note"])
    return pd.DataFrame(rows, columns=["File", "Type", "MIME", "Size", "Note"]).sort_values("Type")


# =====================================================
# Cache clear
# =====================================================
def clear_results_cache():
    for k in list(st.session_state.keys()):
        if k.startswith("cache_"):
            st.session_state.pop(k, None)
    try:
        st.cache_data.clear()
    except Exception:
        pass


# =====================================================
# Models
# =====================================================
class VAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, latent_dim * 2)

    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        h2 = F.relu(self.fc2(h1))
        h3 = self.fc3(h2)
        mean, log_var = torch.chunk(h3, 2, dim=-1)
        return mean, log_var

    def reparameterize(self, mean, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mean + eps * std

    def forward(self, x):
        mean, log_var = self.encode(x)
        z = self.reparameterize(mean, log_var)
        return z, mean, log_var


class MLP(nn.Module):
    def __init__(self, latent_dim):
        super().__init__()
        self.fc1 = nn.Linear(latent_dim, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 1)

    def forward(self, z):
        z = F.relu(self.fc1(z))
        z = F.relu(self.fc2(z))
        return torch.sigmoid(self.fc3(z))


# =====================================================
# Sticky Toolbar (anchor nav + scroll highlight)
# =====================================================
def render_sticky_toolbar():
    run_ok = "cache_stability_df" in st.session_state
    data_source = st.session_state.get("cache_data_source", "æœªè¿è¡Œ")
    cached_at = st.session_state.get("cache_cached_at", "")

    status_badge = "å·²è¿è¡Œ" if run_ok else "æœªè¿è¡Œ"
    status_color = "#16A34A" if run_ok else "#F59E0B"

    html = f"""
    <style>
      .block-container {{ padding-top: 6.6rem; }}
      .stickybar {{
        position: fixed;
        top: 0; left: 0; right: 0;
        z-index: 9999;
        background: rgba(255,255,255,0.86);
        backdrop-filter: blur(10px);
        border-bottom: 1px solid rgba(15,23,42,0.10);
      }}
      .sticky-inner {{
        max-width: 1400px;
        margin: 0 auto;
        padding: 10px 18px;
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 14px;
        font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      }}
      .left {{ display:flex; align-items:center; gap:10px; min-width: 320px; flex-wrap: wrap; }}
      .brand {{ font-weight:800; letter-spacing:-0.02em; color:#0F172A; font-size:14px; white-space:nowrap; }}
      .badge {{
        display:inline-flex; align-items:center; gap:6px;
        padding:6px 10px; border-radius:999px;
        border: 1px solid rgba(15,23,42,0.12);
        background: rgba(255,255,255,0.70);
        font-size:12px; white-space:nowrap;
      }}
      .dot {{ width:8px; height:8px; border-radius:999px; background:{status_color}; display:inline-block; }}
      .right {{ display:flex; align-items:center; gap:8px; flex-wrap: wrap; justify-content:flex-end; }}
      .btn {{
        display:inline-flex; align-items:center; gap:8px;
        padding:8px 10px; border-radius:10px;
        border: 1px solid rgba(15,23,42,0.12);
        background: rgba(255,255,255,0.70);
        color:#0F172A; text-decoration:none;
        font-size:12px; cursor:pointer;
        transition: all .12s ease; user-select:none;
      }}
      .btn:hover {{ background: rgba(246,248,252,0.95); transform: translateY(-1px); }}
      .btn.primary {{ border-color: rgba(46,125,255,0.35); background: rgba(46,125,255,0.10); }}

      /* highlight by scroll (active) */
      .btn.active {{
        border-color: rgba(37,99,235,0.60);
        background: linear-gradient(135deg, rgba(37,99,235,0.22), rgba(59,130,246,0.14));
        box-shadow: 0 10px 22px rgba(37,99,235,0.16);
        color: #1D4ED8;
      }}
      .muted {{ opacity:0.65; font-size:12px; white-space:nowrap; }}
      .sep {{ width:1px; height:20px; background: rgba(15,23,42,0.10); margin:0 4px; }}
    </style>

    <div class="stickybar">
      <div class="sticky-inner">
        <div class="left">
          <div class="brand">ğŸ§¬ VAEjMLP BioApp</div>
          <div class="badge"><span class="dot"></span>{status_badge}</div>
          <div class="badge">æ•°æ®æºï¼š{data_source}</div>
          <div class="badge">ç¼“å­˜ï¼š{cached_at if cached_at else "â€”"}</div>
        </div>

        <div class="right">
          <a class="btn primary" href="#run">ğŸš€ è¿è¡ŒåŒº</a>
          <div class="sep"></div>
          <a class="btn nav" id="nav-main" href="#main">â‘  ä¸»æµç¨‹</a>
          <a class="btn nav" id="nav-download" href="#download">â‘¡ ä¸‹è½½</a>
          <a class="btn nav" id="nav-enrich" href="#enrich">â‘¢ å¯Œé›†</a>
          <a class="btn nav" id="nav-de" href="#de">â‘£ å·®å¼‚</a>
          <a class="btn nav" id="nav-survival" href="#survival">â‘¤ ç”Ÿå­˜</a>
          <div class="sep"></div>
          <a class="btn" href="#top">â¬† å›åˆ°é¡¶éƒ¨</a>
          <span class="muted">æ»šåŠ¨é«˜äº®</span>
        </div>
      </div>
    </div>

    <script>
      const sections = [
        ["main", "nav-main"],
        ["download", "nav-download"],
        ["enrich", "nav-enrich"],
        ["de", "nav-de"],
        ["survival", "nav-survival"],
      ];
      function setActive(btnId) {{
        sections.forEach(([sec, id]) => {{
          const el = document.getElementById(id);
          if (el) el.classList.remove("active");
        }});
        const active = document.getElementById(btnId);
        if (active) active.classList.add("active");
      }}
      sections.forEach(([secId, btnId]) => {{
        const target = document.getElementById(secId);
        if (!target) return;
        const obs = new IntersectionObserver((entries) => {{
          entries.forEach(entry => {{
            if (entry.isIntersecting) setActive(btnId);
          }});
        }}, {{
          root: null,
          threshold: 0.01,
          rootMargin: "-35% 0px -60% 0px"
        }});
        obs.observe(target);
      }});
      setActive("nav-main");
    </script>
    """
    components.html(html, height=0)


# =====================================================
# Page + Styles
# =====================================================
st.set_page_config(page_title="VAEjMLP latent-SHAP BioApp", layout="wide")
st.markdown('<div id="top"></div>', unsafe_allow_html=True)
render_sticky_toolbar()
artifacts_init()

st.markdown(
    """
    <style>
      .block-container { padding-bottom: 2rem; max-width: 1400px; }
      h1, h2, h3 { letter-spacing: -0.01em; }

      .heroWrap {
        border: 1px solid rgba(49,51,63,0.10);
        border-radius: 18px;
        padding: 18px 18px 8px 18px;
        background: linear-gradient(180deg, rgba(255,255,255,0.80), rgba(255,255,255,0.50));
        box-shadow: 0 1px 16px rgba(0,0,0,0.03);
        margin-bottom: 14px;
      }
      .heroTitle { font-size: 20px; font-weight: 800; margin: 0 0 6px 0; }
      .heroSub { opacity: 0.75; margin: 0 0 12px 0; }

      .card {
        border: 1px solid rgba(49,51,63,0.12);
        border-radius: 16px;
        padding: 14px 14px;
        background: rgba(255,255,255,0.66);
        backdrop-filter: blur(6px);
        box-shadow: 0 1px 10px rgba(0,0,0,0.02);
        margin-bottom: 14px;
      }

      .kpi {
        border: 1px solid rgba(49,51,63,0.15);
        border-radius: 14px;
        padding: 14px 16px;
        background: rgba(255,255,255,0.6);
        backdrop-filter: blur(6px);
        box-shadow: 0 1px 10px rgba(0,0,0,0.03);
      }
      .kpi .label { font-size: 0.85rem; opacity: 0.7; }
      .kpi .value { font-size: 1.3rem; font-weight: 800; margin-top: 2px; }
      .kpi .hint  { font-size: 0.8rem; opacity: 0.55; margin-top: 6px; }

      .smallMuted { opacity: 0.70; font-size: 0.90rem; }
      .stDataFrame { border-radius: 12px; overflow: hidden; }

      /* ---- module buttons: make active state obvious; no checkmark used ---- */
      .modbtn-row { display:flex; gap:10px; flex-wrap: wrap; margin: 8px 0 12px 0; }
      /* Streamlit button styling hook (best-effort) */
      div[data-testid="stButton"] > button.modbtn {
        border: 1px solid rgba(15,23,42,0.14) !important;
        background: rgba(255,255,255,0.72) !important;
        color: #0F172A !important;
        border-radius: 14px !important;
        padding: 0.55rem 0.8rem !important;
        font-weight: 800 !important;
        transition: all .14s ease !important;
      }
      div[data-testid="stButton"] > button.modbtn:hover {
        transform: translateY(-1px) !important;
        box-shadow: 0 10px 22px rgba(2,6,23,0.06) !important;
        border-color: rgba(37,99,235,0.35) !important;
        background: rgba(246,248,252,0.96) !important;
      }
      div[data-testid="stButton"] > button.modbtn.active {
        border-color: rgba(37,99,235,0.60) !important;
        background: linear-gradient(135deg, rgba(37,99,235,0.22), rgba(59,130,246,0.14)) !important;
        box-shadow: 0 12px 26px rgba(37,99,235,0.16) !important;
        color: #1D4ED8 !important;
      }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ§¬ VAEjMLP + latent SHAP ç”Ÿç‰©æ ‡å¿—ç‰©åˆ†æå¹³å°")
st.caption("Latent è¡¨å¾å­¦ä¹  â†’ è§£é‡Šæ€§ï¼ˆSHAPï¼‰â†’ ç¨³å®šæ€§è¯„ä¼° â†’ åŠŸèƒ½å¯Œé›†ï¼ˆæŒ‰é’®åˆ‡æ¢+æ°”æ³¡å›¾ï¼‰â†’ å·®å¼‚åˆ†æï¼ˆå«ç®±çº¿å›¾ï¼‰â†’ èšç±»ä¸ç”Ÿå­˜éªŒè¯")


# =====================================================
# Sidebar: Demo gate + Clear cache
# =====================================================
with st.sidebar:
    st.header("ç¤ºä¾‹æ•°æ®")
    use_demo_gate = st.checkbox("ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆDemoï¼‰", value=False)
    st.divider()
    st.header("ç¼“å­˜ç®¡ç†")
    if st.button("ğŸ§¹ æ¸…é™¤ç¼“å­˜ / æ¸…é™¤ç»“æœ", use_container_width=True):
        clear_results_cache()
        st.success("å·²æ¸…é™¤è¿è¡Œç»“æœä¸ä¸‹è½½ç¼“å­˜ã€‚")
        st.rerun()
    st.caption("è¯´æ˜ï¼šæ¸…é™¤ä¸ä¼šå½±å“é¡µé¢å¼€å…³ï¼Œåªä¼šæ¸…æ‰å·²è¿è¡Œç»“æœä¸ä¸‹è½½æ–‡ä»¶ç¼“å­˜ã€‚")

if not use_demo_gate:
    st.markdown(
        """
        <div class="card">
          <div class="heroTitle">æ•´ä½“å·¥ä½œä»‹ç»</div>
          <div class="smallMuted">
            æœ¬å·¥å…·é¢å‘ RNA-seq è¡¨è¾¾çŸ©é˜µï¼ˆgenesÃ—samplesï¼‰ä¸äºŒåˆ†ç±»æ ‡ç­¾ï¼Œè®­ç»ƒ <b>VAE + MLP</b> å­¦ä¹  latent è¡¨å¾ï¼›
            ä½¿ç”¨ <b>latent SHAP</b> è§£é‡Šæ¨¡å‹å†³ç­–å¹¶æ˜ å°„å›åŸºå› å±‚å½¢æˆå€™é€‰ biomarkersï¼›
            æ”¯æŒå¤šæ¬¡è¿è¡Œåšç¨³å®šæ€§è¯„ä¼°ï¼ˆé¢‘ç‡/CVï¼‰ï¼›å¹¶å¯¹ Top20 åšå¯Œé›†ã€å·®å¼‚ï¼ˆå«ç®±çº¿å›¾ï¼‰ã€èšç±»åŠç”Ÿå­˜éªŒè¯ã€‚
          </div>
          <div class="smallMuted" style="margin-top:10px;">ğŸ‘‰ è¯·åœ¨å·¦ä¾§æ‰“å¼€ã€Œä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆDemoï¼‰ã€è¿›å…¥å®Œæ•´é¡µé¢ã€‚</div>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.stop()


# =====================================================
# Sidebar: parameters
# =====================================================
with st.sidebar:
    st.divider()
    st.header("ä¸»æµç¨‹å‚æ•°")
    latent_dim = st.number_input("latent_dim", min_value=4, max_value=1024, value=128, step=4)
    n_epochs = st.number_input("è®­ç»ƒè½®æ•° epochs", min_value=10, max_value=2000, value=100, step=10)
    lr = st.number_input("å­¦ä¹ ç‡ lr", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-4, format="%.5f")
    ce_weight = st.number_input("CE æƒé‡ï¼ˆloss = KL + ce_weight*CEï¼‰", min_value=0.0, max_value=10.0, value=0.001, step=0.001)
    test_size = st.slider("test_size", 0.05, 0.5, 0.2, 0.05)

    st.subheader("ç¨³å®šæ€§ (multi-run)")
    n_runs = st.slider("é‡å¤è¿è¡Œæ¬¡æ•° n_runs", 1, 50, 10)
    top_k = st.slider("TopK é¢‘ç‡ç»Ÿè®¡", 5, 300, 20)
    seed_base = st.number_input("seed_base", value=42, step=1)

    st.subheader("SHAP è®¡ç®—")
    background_n = st.slider("background æ ·æœ¬æ•°", 10, 200, 50)
    shap_nsamples = st.slider("KernelExplainer nsamples", 50, 500, 100, 50)

    st.divider()
    st.header("èšç±»/ç”Ÿå­˜å‚æ•°")
    cluster_k = st.slider("èšç±»ç°‡æ•° K", 2, 6, 2)
    cox_penalizer = st.number_input("Cox L2 penalizer", min_value=0.0, max_value=10.0, value=0.1, step=0.1)


# =====================================================
# Hero section: Input / Workflow / Output
# =====================================================
st.markdown('<div class="heroWrap">', unsafe_allow_html=True)
st.markdown('<div class="heroTitle">ä¸€ç«™å¼ Biomarker å‘ç°ä¸éªŒè¯</div>', unsafe_allow_html=True)
st.markdown('<div class="heroSub">ä»è¡¨è¾¾çŸ©é˜µåˆ°å¯è§£é‡Šæ€§ã€ç¨³å®šæ€§ä¸éªŒè¯åˆ†æï¼ˆå¯Œé›†/å·®å¼‚/èšç±»/ç”Ÿå­˜ï¼‰</div>', unsafe_allow_html=True)

hc1, hc2, hc3 = st.columns(3)
with hc1:
    st.markdown(
        """
        <div class="card">
          <b>Input</b>
          <div class="smallMuted" style="margin-top:8px;">
            <ul>
              <li>RNA: genes Ã— samplesï¼ˆCSVï¼‰</li>
              <li>Labels: Sample / Labelï¼ˆCSVï¼‰</li>
              <li>Survival: Sample / Time / Eventï¼ˆå¯é€‰ï¼‰</li>
            </ul>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
with hc2:
    st.markdown(
        """
        <div class="card">
          <b>Workflow</b>
          <div class="smallMuted" style="margin-top:8px;">
            VAE å‹ç¼© â†’ MLP åˆ†ç±» â†’ latent SHAP â†’ æ˜ å°„å›åŸºå›  â†’ å¤šæ¬¡è¿è¡Œç¨³å®šæ€§
          </div>
          <div class="smallMuted" style="margin-top:10px;">
            ä¸‹æ¸¸ï¼šGO/KEGGã€å·®å¼‚ï¼ˆå«ç®±çº¿å›¾ï¼‰ã€Top20 èšç±»ã€ç”Ÿå­˜éªŒè¯
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
with hc3:
    st.markdown(
        """
        <div class="card">
          <b>Output</b>
          <div class="smallMuted" style="margin-top:8px;">
            <ul>
              <li>æ€§èƒ½æŒ‡æ ‡ï¼ˆAUC/Acc/Prec/Recallï¼‰</li>
              <li>Top biomarkers + ç¨³å®šæ€§ï¼ˆFreq/CVï¼‰</li>
              <li>SHAP å›¾ã€å¯Œé›†/å·®å¼‚/èšç±»/ç”Ÿå­˜</li>
              <li>CSV/PNG/ZIP + REPORT.md</li>
            </ul>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
st.markdown("</div>", unsafe_allow_html=True)


# =====================================================
# Uploaders + RUN (Anchor: run)
# =====================================================
st.markdown('<div id="run"></div>', unsafe_allow_html=True)
st.markdown('<div class="card">', unsafe_allow_html=True)
st.markdown("### æ•°æ®è¾“å…¥")

u1, u2, u3 = st.columns(3)
with u1:
    rna_file = st.file_uploader("RNA-seqï¼ˆgenesÃ—samplesï¼‰CSVï¼ˆå¯é€‰ï¼‰", type="csv", key="rna_uploader")
with u2:
    label_file = st.file_uploader("Labels CSVï¼ˆSample/Labelï¼Œå¯é€‰ï¼‰", type="csv", key="label_uploader")
with u3:
    surv_file = st.file_uploader("Survival CSVï¼ˆSample,Time,Eventï¼Œå¯é€‰ï¼‰", type="csv", key="surv_uploader")

use_demo_data = st.checkbox("æœ¬æ¬¡è¿è¡Œä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆå¿½ç•¥ä¸Šä¼ ï¼‰", value=True)
run_button = st.button("ğŸš€ è¿è¡Œä¸»æµç¨‹", type="primary")
st.markdown("</div>", unsafe_allow_html=True)


# =====================================================
# Main pipeline
# =====================================================
if run_button:
    st.session_state["cache_params"] = {
        "latent_dim": int(latent_dim),
        "epochs": int(n_epochs),
        "lr": float(lr),
        "ce_weight": float(ce_weight),
        "test_size": float(test_size),
        "n_runs": int(n_runs),
        "top_k": int(top_k),
        "seed_base": int(seed_base),
        "background_n": int(background_n),
        "shap_nsamples": int(shap_nsamples),
        "cluster_k": int(cluster_k),
        "cox_penalizer": float(cox_penalizer),
    }

    if use_demo_data:
        rna_path = os.path.join(DEMO_DIR, DEMO_RNA)
        lab_path = os.path.join(DEMO_DIR, DEMO_LAB)
        sur_path = os.path.join(DEMO_DIR, DEMO_SUR)

        if (not os.path.exists(rna_path)) or (not os.path.exists(lab_path)):
            st.error(
                "ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ã€‚è¯·æŠŠç¤ºä¾‹æ–‡ä»¶æ”¾åœ¨ app.py åŒç›®å½•ï¼š\n"
                f"- {rna_path}\n- {lab_path}\n- {sur_path}ï¼ˆå¯é€‰ï¼‰"
            )
            st.stop()

        with st.spinner("è¯»å–ç¤ºä¾‹æ•°æ®ä¸­..."):
            rna_raw = read_csv_path_cached(rna_path)
            labels_raw = read_csv_path_cached(lab_path)

        st.session_state["cache_demo_surv_raw"] = read_csv_path_cached(sur_path) if os.path.exists(sur_path) else None
        st.session_state["cache_data_source"] = "Demo"
    else:
        st.session_state["cache_demo_surv_raw"] = None
        if rna_file is None or label_file is None:
            st.error("æœªé€‰æ‹©ç¤ºä¾‹æ•°æ®æ—¶ï¼Œå¿…é¡»ä¸Šä¼  RNA ä¸ Labelã€‚")
            st.stop()
        with st.spinner("è¯»å–ä¸Šä¼ æ•°æ®ä¸­..."):
            rna_raw = read_csv_cached(rna_file)
            labels_raw = read_csv_cached(label_file)
        st.session_state["cache_data_source"] = "Upload"

    with st.spinner("å¯¹é½æ ·æœ¬ä¸åˆ—è¯†åˆ«ä¸­..."):
        try:
            rna, labels, align_info, label_detect = align_rna_labels(rna_raw, labels_raw)
        except Exception as e:
            st.error(f"æ•°æ®å¯¹é½å¤±è´¥ï¼š{e}")
            st.stop()

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### âœ… è¾“å…¥æ£€æŸ¥ä¸å¯¹é½ä¿¡æ¯")
    st.write({
        "æ ·æœ¬å¯¹é½": align_info,
        "å¯¹é½å RNA ç»´åº¦ (genesÃ—samples)": f"{rna.shape[0]} Ã— {rna.shape[1]}",
    })
    if align_info.get("took_intersection", False):
        st.warning("RNA ä¸ Labels æ ·æœ¬ä¸å®Œå…¨ä¸€è‡´ï¼šå·²è‡ªåŠ¨å–äº¤é›†å¹¶æŒ‰ RNA åˆ—é¡ºåºå¯¹é½ã€‚")
    st.markdown("</div>", unsafe_allow_html=True)

    genes = rna.index.astype(str).tolist()
    y = labels["Label"].values
    X = MinMaxScaler().fit_transform(rna.T.values)

    st.session_state["cache_artifacts"] = {}
    st.session_state["cache_fig_pngs"] = {}

    all_importances, topk_lists, metrics_runs = [], [], []
    last_shap_z, last_z_test, last_latent_df = None, None, None

    prog = st.progress(0)
    status = st.empty()

    with st.spinner("è®­ç»ƒä¸ SHAP è®¡ç®—ä¸­..."):
        for run_i in range(int(n_runs)):
            seed = int(seed_base + run_i)
            set_seed(seed)
            status.write(f"Run {run_i+1}/{n_runs} | seed={seed}")

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=float(test_size), random_state=seed,
                stratify=y if len(pd.Series(y).unique()) == 2 else None
            )

            X_train_t = torch.tensor(X_train, dtype=torch.float32)
            X_test_t = torch.tensor(X_test, dtype=torch.float32)
            y_train_t = torch.tensor(pd.Series(y_train).astype(float).values, dtype=torch.float32).view(-1, 1)

            vae = VAE(X.shape[1], int(latent_dim))
            mlp = MLP(int(latent_dim))
            optimizer = optim.Adam(list(vae.parameters()) + list(mlp.parameters()), lr=float(lr))

            vae.train()
            mlp.train()
            for _ in range(int(n_epochs)):
                optimizer.zero_grad()
                z, mean, log_var = vae(X_train_t)
                y_pred = mlp(z)
                kl = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())
                ce = F.binary_cross_entropy(y_pred, y_train_t, reduction="sum")
                loss = kl + float(ce_weight) * ce
                loss.backward()
                optimizer.step()

            vae.eval()
            mlp.eval()
            with torch.no_grad():
                z_test, _, _ = vae(X_test_t)
                y_pred_test = mlp(z_test).cpu().numpy().flatten()

            try:
                auc = roc_auc_score(y_test, y_pred_test)
            except Exception:
                auc = np.nan

            y_hat = (y_pred_test > 0.5).astype(int)
            metrics_runs.append({
                "run": run_i, "seed": seed,
                "AUC": auc,
                "Accuracy": accuracy_score(y_test, y_hat),
                "Precision": precision_score(y_test, y_hat, zero_division=0),
                "Recall": recall_score(y_test, y_hat, zero_division=0),
            })

            with torch.no_grad():
                z_train, _, _ = vae(X_train_t)
            z_train_np = z_train.cpu().numpy()
            z_test_np = z_test.cpu().numpy()

            def mlp_predict(z_numpy):
                z_t = torch.tensor(z_numpy, dtype=torch.float32)
                with torch.no_grad():
                    out = mlp(z_t).cpu().numpy()
                return out.reshape(-1)

            bg_n = int(min(background_n, z_train_np.shape[0]))
            background_z = shap.sample(z_train_np, bg_n)
            explainer = shap.KernelExplainer(mlp_predict, background_z)

            shap_values = explainer.shap_values(z_test_np, nsamples=int(shap_nsamples))
            shap_z = ensure_2d_shap(shap_values, z_test_np)

            W_gene_hidden = vae.fc1.weight.detach().cpu().numpy()
            abs_shap_z = np.mean(np.abs(shap_z), axis=0)
            scale = float(np.sum(abs_shap_z))
            gene_importance = {gene: float(np.mean(np.abs(W_gene_hidden[:, i])) * scale) for i, gene in enumerate(genes)}
            imp_s = pd.Series(gene_importance).reindex(genes)

            all_importances.append(imp_s)
            topk_lists.append(imp_s.sort_values(ascending=False).head(int(top_k)).index.tolist())

            if run_i == int(n_runs) - 1:
                last_shap_z = shap_z
                last_z_test = z_test_np
                abs_latent = np.mean(np.abs(shap_z), axis=0)
                last_latent_df = (
                    pd.DataFrame({"LatentDim": np.arange(len(abs_latent)), "MeanAbsSHAP": abs_latent})
                    .sort_values("MeanAbsSHAP", ascending=False)
                    .reset_index(drop=True)
                )

            prog.progress((run_i + 1) / int(n_runs))

    status.empty()
    prog.empty()

    metrics_df = pd.DataFrame(metrics_runs)
    summary_df = metrics_df[["AUC", "Accuracy", "Precision", "Recall"]].agg(["mean", "std"]).T.reset_index()
    summary_df.columns = ["Metric", "Mean", "Std"]

    imp_mat = pd.concat(all_importances, axis=1)
    imp_mat.columns = [f"run_{i}" for i in range(int(n_runs))]
    mean_imp = imp_mat.mean(axis=1)
    std_imp = imp_mat.std(axis=1)
    cv_imp = std_imp / (mean_imp.abs() + 1e-12)

    from collections import Counter
    freq_counter = Counter([g for lst in topk_lists for g in lst])
    freq = pd.Series({g: freq_counter.get(g, 0) / float(n_runs) for g in genes})
    freq_col = f"Top{int(top_k)}_Freq"

    stability_df = pd.DataFrame({
        "Gene": genes,
        "MeanImportance": mean_imp.values,
        "StdImportance": std_imp.values,
        "CV": cv_imp.values,
        freq_col: freq.values,
    }).sort_values([freq_col, "MeanImportance"], ascending=[False, False]).reset_index(drop=True)

    top20_genes = stability_df.sort_values("MeanImportance", ascending=False)["Gene"].head(20).tolist()

    # cache
    st.session_state["cache_rna"] = rna
    st.session_state["cache_labels"] = labels
    st.session_state["cache_top20_genes"] = top20_genes
    st.session_state["cache_metrics_df"] = metrics_df
    st.session_state["cache_summary_df"] = summary_df
    st.session_state["cache_stability_df"] = stability_df
    st.session_state["cache_latent_df"] = last_latent_df
    st.session_state["cache_last_shap_z"] = last_shap_z
    st.session_state["cache_last_z_test"] = last_z_test
    st.session_state["cache_cached_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # artifacts
    artifact_put_df_csv("model_metrics_all_runs.csv", metrics_df, note="æ¯æ¬¡ run çš„æŒ‡æ ‡")
    artifact_put_df_csv("model_metrics_summary.csv", summary_df, note="æŒ‡æ ‡å‡å€¼Â±æ ‡å‡†å·®")
    artifact_put_df_csv("latent_shap_gene_importance_stability.csv", stability_df, note="åŸºå› ç¨³å®šæ€§ï¼ˆMean/CV/Freqï¼‰")
    if isinstance(last_latent_df, pd.DataFrame):
        artifact_put_df_csv("latent_mean_abs_shap.csv", last_latent_df, note="latent ç»´åº¦ MeanAbsSHAP")

    try:
        if last_shap_z is not None and last_z_test is not None:
            fig1 = plt.figure(figsize=(9.5, 5.5))
            shap.summary_plot(last_shap_z, features=last_z_test, show=False)
            artifact_put_fig_png("shap_summary_dot.png", fig1, note="SHAP summary dot")
            plt.close(fig1)

            fig2 = plt.figure(figsize=(9.5, 5.0))
            shap.summary_plot(last_shap_z, features=last_z_test, plot_type="bar", show=False)
            artifact_put_fig_png("shap_summary_bar.png", fig2, note="SHAP summary bar")
            plt.close(fig2)
    except Exception:
        pass

    # clear downstream caches
    for k in [
        "cache_enrich_go_kegg",
        "cache_enrich_lib_idx",
        "cache_de_df",
        "cache_de_groups",
        "cache_cluster_df",
        "cache_cluster_X_scaled",
        "cache_cox_cluster_summary",
    ]:
        st.session_state.pop(k, None)

    # default page
    st.session_state["page"] = "ä¸»æµç¨‹"
    st.success("âœ… ä¸»æµç¨‹è¿è¡Œå®Œæˆï¼šç»“æœå·²ç¼“å­˜ï¼ˆåˆ‡æ¢é¡µé¢/ä¸‹è½½ä¸ä¼šä¸¢å¤±ï¼‰ã€‚")
    st.rerun()


# =====================================================
# KPI cards
# =====================================================
if "cache_metrics_df" in st.session_state:
    sdf = st.session_state["cache_summary_df"]
    auc_mean = float(sdf.loc[sdf["Metric"] == "AUC", "Mean"].values[0]) if "AUC" in sdf["Metric"].values else np.nan
    acc_mean = float(sdf.loc[sdf["Metric"] == "Accuracy", "Mean"].values[0]) if "Accuracy" in sdf["Metric"].values else np.nan
    top20 = st.session_state.get("cache_top20_genes", [])

    st.markdown('<div class="card">', unsafe_allow_html=True)
    k1, k2, k3, k4 = st.columns(4)
    with k1:
        st.markdown(
            f"""<div class="kpi"><div class="label">Runs</div><div class="value">{len(st.session_state["cache_metrics_df"])}</div><div class="hint">é‡å¤è®­ç»ƒæ¬¡æ•°</div></div>""",
            unsafe_allow_html=True,
        )
    with k2:
        st.markdown(
            f"""<div class="kpi"><div class="label">AUC (mean)</div><div class="value">{auc_mean:.3f}</div><div class="hint">æµ‹è¯•é›†å¹³å‡ AUC</div></div>""",
            unsafe_allow_html=True,
        )
    with k3:
        st.markdown(
            f"""<div class="kpi"><div class="label">Accuracy (mean)</div><div class="value">{acc_mean:.3f}</div><div class="hint">æµ‹è¯•é›†å¹³å‡å‡†ç¡®ç‡</div></div>""",
            unsafe_allow_html=True,
        )
    with k4:
        st.markdown(
            f"""<div class="kpi"><div class="label">Top biomarkers</div><div class="value">{len(top20)}</div><div class="hint">ç”¨äºä¸‹æ¸¸åˆ†æ</div></div>""",
            unsafe_allow_html=True,
        )
    st.markdown("</div>", unsafe_allow_html=True)


# =====================================================
# Button Navigation (replaces Tabs) â€” NO CHECKMARK
# =====================================================
PAGES = ["ä¸»æµç¨‹", "ä¸‹è½½ä¸­å¿ƒ", "åŠŸèƒ½å¯Œé›†", "å·®å¼‚åˆ†æ", "èšç±»&ç”Ÿå­˜"]
if "page" not in st.session_state:
    st.session_state["page"] = "ä¸»æµç¨‹"

st.markdown('<div class="card">', unsafe_allow_html=True)
st.markdown("### æ¨¡å—å¯¼èˆªï¼ˆæŒ‰é’®ï¼‰")

cols = st.columns([1, 1, 1, 1, 1])
for i, p in enumerate(PAGES):
    with cols[i]:
        is_active = (st.session_state["page"] == p)

        # å…³é”®ï¼šä¸åŠ  âœ…ï¼Œä»…ç”¨é¢œè‰²åŒºåˆ†
        btn_label = p

        # ç”¨ key åŒºåˆ†ï¼›å¹¶ç”¨ JS ç»™å½“å‰æŒ‰é’®åŠ  class activeï¼ˆCSS æ§åˆ¶æ˜æ˜¾é¢œè‰²ï¼‰
        clicked = st.button(btn_label, use_container_width=True, key=f"nav_{p}")
        if clicked:
            st.session_state["page"] = p
            st.rerun()

        # ç»™æ¸²æŸ“å‡ºæ¥çš„â€œæœ€åä¸€ä¸ªæŒ‰é’®â€æ‰“æ ‡ç­¾ä¸å¤ªå¯é ï¼Œé‡‡ç”¨ JSï¼šæŒ‰æ–‡æœ¬åŒ¹é…å¹¶ç»™ active åŠ  class
        # è¿™æ®µæ¯æ¬¡éƒ½ä¼šè·‘ä¸€éï¼Œç¡®ä¿å½“å‰é€‰ä¸­æ€ç”Ÿæ•ˆ
        if is_active:
            components.html(
                f"""
                <script>
                  const btns = parent.document.querySelectorAll('button');
                  btns.forEach(b => {{
                    if (b.innerText.trim() === "{p}") {{
                      b.classList.add("modbtn");
                      b.classList.add("active");
                    }} else if (b.classList.contains("modbtn")) {{
                      // åªç§»é™¤ modbtn çš„ activeï¼Œä¸å½±å“å…¶ä»–æŒ‰é’®
                      b.classList.remove("active");
                    }}
                  }});
                </script>
                """,
                height=0,
            )
        else:
            # ensure modbtn class exists for consistent style
            components.html(
                f"""
                <script>
                  const btns = parent.document.querySelectorAll('button');
                  btns.forEach(b => {{
                    if (b.innerText.trim() === "{p}") {{
                      b.classList.add("modbtn");
                    }}
                  }});
                </script>
                """,
                height=0,
            )

st.markdown("</div>", unsafe_allow_html=True)


def _need_run():
    st.info("è¯·å…ˆè¿è¡Œä¸»æµç¨‹ï¼ˆç‚¹å‡»ä¸Šæ–¹ ğŸš€ è¿è¡Œä¸»æµç¨‹ï¼‰ã€‚")


# =====================================================
# Render pages
# =====================================================
def render_main():
    st.markdown('<div id="main"></div>', unsafe_allow_html=True)
    st.subheader("â‘  ä¸»æµç¨‹ï¼ˆæ€§èƒ½ / ç¨³å®šæ€§ / SHAPï¼‰")
    if "cache_stability_df" not in st.session_state:
        _need_run()
        return

    metrics_df = st.session_state["cache_metrics_df"]
    summary_df = st.session_state["cache_summary_df"]
    stability_df = st.session_state["cache_stability_df"]
    top20 = st.session_state["cache_top20_genes"]
    last_shap_z = st.session_state.get("cache_last_shap_z", None)
    last_z_test = st.session_state.get("cache_last_z_test", None)
    latent_df = st.session_state.get("cache_latent_df", None)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ“Š æ¨¡å‹æ€§èƒ½ï¼ˆæ¯æ¬¡ runï¼‰")
    st.dataframe(metrics_df, use_container_width=True, height=260)
    st.markdown("#### ğŸ“Š æŒ‡æ ‡æ±‡æ€»ï¼ˆå‡å€¼Â±æ ‡å‡†å·®ï¼‰")
    st.dataframe(summary_df, use_container_width=True, height=210)
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ§¬ Top20 å€™é€‰ç”Ÿç‰©æ ‡å¿—ç‰©ï¼ˆMeanImportanceï¼‰")
    st.code("\n".join(top20))
    st.markdown("#### ğŸ“Œ ç¨³å®šæ€§ï¼ˆFrequency / CVï¼‰Top50")
    st.dataframe(stability_df.head(50), use_container_width=True, height=420)
    st.markdown("</div>", unsafe_allow_html=True)

    if last_shap_z is not None and last_z_test is not None:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ğŸ” Latent SHAP Summaryï¼ˆdot / barï¼‰")
        fig1 = plt.figure(figsize=(9.5, 5.5))
        shap.summary_plot(last_shap_z, features=last_z_test, show=False)
        st.pyplot(fig1)
        plt.close(fig1)

        fig2 = plt.figure(figsize=(9.5, 5.0))
        shap.summary_plot(last_shap_z, features=last_z_test, plot_type="bar", show=False)
        st.pyplot(fig2)
        plt.close(fig2)
        st.markdown("</div>", unsafe_allow_html=True)

    if isinstance(latent_df, pd.DataFrame):
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ğŸ“ˆ Top latent ç»´åº¦ï¼ˆMeanAbsSHAPï¼‰")
        st.dataframe(latent_df.head(20), use_container_width=True, height=360)
        st.markdown("</div>", unsafe_allow_html=True)


def render_download():
    st.markdown('<div id="download"></div>', unsafe_allow_html=True)
    st.subheader("â‘¡ ä¸‹è½½ä¸­å¿ƒï¼ˆæ–‡ä»¶åˆ—è¡¨ / å•æ–‡ä»¶ / ZIP + REPORTï¼‰")
    if "cache_stability_df" not in st.session_state:
        _need_run()
        return

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ“¦ ç»“æœæ–‡ä»¶åˆ—è¡¨ï¼ˆå½“å‰ sessionï¼‰")
    st.dataframe(artifact_table_df(), use_container_width=True, height=320)
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### â¬‡ å•æ–‡ä»¶ä¸‹è½½")
    cols = st.columns(3)
    artifacts = st.session_state.get("cache_artifacts", {})
    if artifacts:
        names = list(artifacts.keys())
        for i, name in enumerate(names):
            meta = artifacts[name]
            with cols[i % 3]:
                st.download_button(f"â¬‡ {name}", meta["bytes"], name, mime=meta["mime"])
    else:
        st.info("å½“å‰æ²¡æœ‰å¯ä¸‹è½½æ–‡ä»¶ã€‚")
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ§¾ ZIP æ‰“åŒ…ï¼ˆå« REPORT.mdï¼‰")
    ts = now_stamp()
    zip_name = f"results_{ts}.zip"
    zip_bytes = build_results_zip(ts)
    st.download_button("â¬‡ ä¸‹è½½ ZIPï¼ˆresults_*.zipï¼‰", zip_bytes, zip_name, mime="application/zip")
    with st.expander("é¢„è§ˆ REPORT.mdï¼ˆä¼šåŒ…å«åœ¨ ZIPï¼‰"):
        st.markdown(build_report_md())
    st.markdown("</div>", unsafe_allow_html=True)


def render_enrich():
    st.markdown('<div id="enrich"></div>', unsafe_allow_html=True)
    st.subheader("â‘¢ GO / KEGG å¯Œé›†åˆ†æï¼ˆTop20ï¼ŒæŒ‰é’®åˆ‡æ¢ + æ°”æ³¡å›¾ï¼‰")
    if "cache_top20_genes" not in st.session_state:
        _need_run()
        return

    top_genes = st.session_state["cache_top20_genes"]

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### è¾“å…¥åŸºå› ï¼ˆTop20ï¼‰")
    st.code("\n".join(top_genes))
    org = st.selectbox("ç‰©ç§ï¼ˆEnrichr organismï¼‰", ["Human", "Mouse"], index=0)
    top_n = st.slider("å±•ç¤ºæ¡ç›®æ•°ï¼ˆTop Nï¼‰", 5, 50, 20, 5)
    st.markdown('<div class="smallMuted">ä¾èµ–ï¼šgseapy + ç½‘ç»œè®¿é—® Enrichrã€‚</div>', unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

    if not GSEAPY_OK:
        st.warning("æœªå®‰è£… gseapyï¼Œæ— æ³•åš GO/KEGGï¼špip install gseapy")
        return

    if st.button("ğŸ§ª è¿è¡Œ GO/KEGGï¼ˆEnrichrï¼‰", type="primary"):
        with st.spinner("å¯Œé›†åˆ†æè¿è¡Œä¸­ï¼ˆéœ€è¦è”ç½‘è®¿é—® Enrichrï¼‰..."):
            try:
                res_dict = run_enrichr(top_genes, organism=org)
                st.session_state["cache_enrich_go_kegg"] = res_dict
                st.session_state["cache_enrich_lib_idx"] = 0
                for lib, df in res_dict.items():
                    artifact_put_df_csv(f"enrichr_{lib}.csv", df, note=f"Enrichr: {lib}")
                st.success("å¯Œé›†å®Œæˆ âœ…")
            except Exception as e:
                st.error(f"å¯Œé›†å¤±è´¥ï¼š{e}")
                return

    if "cache_enrich_go_kegg" not in st.session_state:
        st.info("ç‚¹å‡»ä¸Šé¢çš„ã€Œè¿è¡Œ GO/KEGGã€ç”Ÿæˆç»“æœã€‚")
        return

    res_dict = st.session_state["cache_enrich_go_kegg"]
    libs = list(res_dict.keys())
    if "cache_enrich_lib_idx" not in st.session_state:
        st.session_state["cache_enrich_lib_idx"] = 0

    idx = int(st.session_state["cache_enrich_lib_idx"])
    idx = max(0, min(idx, len(libs) - 1))
    st.session_state["cache_enrich_lib_idx"] = idx

    st.markdown('<div class="card">', unsafe_allow_html=True)
    c1, c2, c3 = st.columns([1, 2, 1])
    with c1:
        if st.button("â¬… ä¸Šä¸€ä¸ªç»“æœ", use_container_width=True, disabled=(idx == 0)):
            st.session_state["cache_enrich_lib_idx"] = idx - 1
            st.rerun()
    with c2:
        st.markdown(f"#### å½“å‰ç»“æœï¼š**{libs[idx]}**  ï¼ˆ{idx+1}/{len(libs)}ï¼‰")
    with c3:
        if st.button("ä¸‹ä¸€ä¸ªç»“æœ â¡", use_container_width=True, disabled=(idx == len(libs) - 1)):
            st.session_state["cache_enrich_lib_idx"] = idx + 1
            st.rerun()
    st.markdown("</div>", unsafe_allow_html=True)

    lib = libs[idx]
    df = res_dict[lib].copy()

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ“Š å¯Œé›†ç»“æœè¡¨ï¼ˆTopï¼‰")
    adjp_col = _pick_col(df, ["Adjusted P-value", "Adjusted P-value "])
    p_col = _pick_col(df, ["P-value", "p_value", "p-value"])
    if adjp_col is not None:
        df_show = df.sort_values(adjp_col, ascending=True).head(int(top_n))
    elif p_col is not None:
        df_show = df.sort_values(p_col, ascending=True).head(int(top_n))
    else:
        df_show = df.head(int(top_n))
    st.dataframe(df_show, use_container_width=True, height=360)

    st.markdown("#### æ°”æ³¡å›¾ï¼ˆTopï¼‰")
    try:
        figb = plot_enrich_bubble(df, title=f"Enrichr Bubble: {lib}", top_n=int(top_n))
        st.pyplot(figb)
        artifact_put_fig_png(f"enrich_bubble_{lib}.png", figb, note=f"Bubble plot: {lib}")
        plt.close(figb)
    except Exception as e:
        st.error(f"æ°”æ³¡å›¾ç»˜åˆ¶å¤±è´¥ï¼š{e}")

    st.download_button(f"â¬‡ ä¸‹è½½ {lib} CSV", df.to_csv(index=False).encode("utf-8"), f"enrichr_{lib}.csv", mime="text/csv")
    st.markdown("</div>", unsafe_allow_html=True)


def render_de():
    st.markdown('<div id="de"></div>', unsafe_allow_html=True)
    st.subheader("â‘£ å·®å¼‚åˆ†æï¼ˆTop20 + ç«å±±å›¾ + ç®±çº¿å›¾ï¼‰")
    if "cache_rna" not in st.session_state or "cache_labels" not in st.session_state:
        _need_run()
        return

    rna = st.session_state["cache_rna"]
    labels = st.session_state["cache_labels"]
    top_genes = st.session_state["cache_top20_genes"]

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ä¾èµ–æ£€æŸ¥")
    st.write({"scipy": SCIPY_OK, "statsmodels": STATSMODELS_OK})
    st.markdown("</div>", unsafe_allow_html=True)

    if not (SCIPY_OK and STATSMODELS_OK):
        st.warning("å·®å¼‚åˆ†æéœ€è¦ï¼špip install scipy statsmodels")
        return

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### è¿è¡Œä¸ç»“æœ")
    if st.button("ğŸ§¬ è¿è¡Œ Top20 å·®å¼‚åˆ†æï¼ˆt-test + FDRï¼‰", type="primary"):
        with st.spinner("å·®å¼‚åˆ†æè®¡ç®—ä¸­..."):
            try:
                de_df, groups = compute_de_top_genes(rna, labels, top_genes)
                st.session_state["cache_de_df"] = de_df
                st.session_state["cache_de_groups"] = groups
                artifact_put_df_csv("top20_differential_expression.csv", de_df, note="Top20 DE (t-test+FDR)")
                st.success("å·®å¼‚åˆ†æå®Œæˆ âœ…")
            except Exception as e:
                st.error(f"å·®å¼‚åˆ†æå¤±è´¥ï¼š{e}")
    st.markdown("</div>", unsafe_allow_html=True)

    if "cache_de_df" in st.session_state:
        de_df = st.session_state["cache_de_df"]

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### å·®å¼‚ç»“æœï¼ˆTop20ï¼‰")
        st.dataframe(de_df, use_container_width=True, height=360)
        st.download_button("â¬‡ ä¸‹è½½å·®å¼‚ç»“æœ", de_df.to_csv(index=False).encode("utf-8"),
                           "top20_differential_expression.csv", mime="text/csv")
        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ç«å±±å›¾ï¼ˆTop20ï¼‰")
        figv = plt.figure(figsize=(7.8, 4.6))
        x = de_df["log2FC"].values
        yv = -np.log10(de_df["p_value"].values + 1e-300)
        plt.scatter(x, yv)
        for _, row in de_df.iterrows():
            plt.text(row["log2FC"], -np.log10(row["p_value"] + 1e-300), row["Gene"], fontsize=8)
        plt.xlabel("log2FC")
        plt.ylabel("-log10(p)")
        plt.title("Volcano (Top20)")
        plt.tight_layout()
        st.pyplot(figv)
        artifact_put_fig_png("de_volcano_top20.png", figv, note="Volcano plot (Top20)")
        plt.close(figv)
        st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ğŸ“¦ Top åŸºå› è¡¨è¾¾ç®±çº¿å›¾ï¼ˆæŒ‰ Label åˆ†ç»„ï¼‰")
    default_sel = top_genes[:6]
    sel_genes = st.multiselect("é€‰æ‹©è¦ç”»çš„åŸºå› ï¼ˆå»ºè®® 3~10 ä¸ªæ›´æ¸…æ™°ï¼‰", options=top_genes, default=default_sel)
    save_png = st.checkbox("æŠŠç®±çº¿å›¾åŠ å…¥ä¸‹è½½ä¸­å¿ƒï¼ˆPNGï¼‰", value=True)
    if st.button("ğŸ“ˆ ç”Ÿæˆç®±çº¿å›¾", type="primary"):
        try:
            fig_box = plot_gene_boxplots(rna, labels, sel_genes)
            st.pyplot(fig_box)
            if save_png:
                artifact_put_fig_png("top_genes_boxplots.png", fig_box, note="Boxplots by Label (selected genes)")
            plt.close(fig_box)
        except Exception as e:
            st.error(f"ç®±çº¿å›¾ç”Ÿæˆå¤±è´¥ï¼š{e}")
    st.markdown("</div>", unsafe_allow_html=True)


def render_survival():
    st.markdown('<div id="survival"></div>', unsafe_allow_html=True)
    st.subheader("â‘¤ èšç±»ï¼ˆTop20ï¼‰+ ç”Ÿå­˜ï¼ˆKM/Coxï¼‰")
    if "cache_rna" not in st.session_state or "cache_top20_genes" not in st.session_state:
        _need_run()
        return

    rna = st.session_state["cache_rna"]
    top_genes = st.session_state["cache_top20_genes"]

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### èšç±»è¾“å…¥ï¼ˆTop20ï¼‰")
    st.code("\n".join(top_genes))
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    if st.button("ğŸ§© è¿è¡Œèšç±»ï¼ˆTop20 åŸºå› è¡¨è¾¾ï¼‰", type="primary"):
        with st.spinner("èšç±»ä¸­..."):
            try:
                cluster_df, X_scaled_df = cluster_samples_by_top_genes(
                    rna=rna, top_genes=top_genes, n_clusters=int(cluster_k), seed=int(seed_base)
                )
                st.session_state["cache_cluster_df"] = cluster_df
                st.session_state["cache_cluster_X_scaled"] = X_scaled_df
                artifact_put_df_csv("top20_cluster_labels.csv", cluster_df, note="KMeans clusters by Top20")
                st.success("èšç±»å®Œæˆ âœ…")
            except Exception as e:
                st.error(f"èšç±»å¤±è´¥ï¼š{e}")
    st.markdown("</div>", unsafe_allow_html=True)

    if "cache_cluster_df" not in st.session_state:
        st.info("å…ˆç‚¹å‡»ã€Œè¿è¡Œèšç±»ã€ç”Ÿæˆ Cluster æ ‡ç­¾ï¼Œç„¶åå†åšç”Ÿå­˜åˆ†æã€‚")
        return

    cluster_df = st.session_state["cache_cluster_df"]
    X_scaled_df = st.session_state.get("cache_cluster_X_scaled", None)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### èšç±»ç»“æœï¼ˆSample â†’ Clusterï¼‰")
    st.dataframe(cluster_df.head(100), use_container_width=True, height=340)
    st.download_button("â¬‡ ä¸‹è½½èšç±»ç»“æœ", cluster_df.to_csv(index=False).encode("utf-8"),
                       "top20_cluster_labels.csv", mime="text/csv")
    st.markdown("</div>", unsafe_allow_html=True)

    if X_scaled_df is not None:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### çƒ­å›¾ï¼ˆz-scoreï¼ŒæŒ‰ Cluster æ’åºï¼‰")
        df_plot = X_scaled_df.copy()
        df_plot["Cluster"] = cluster_df.set_index("Sample").loc[df_plot.index]["Cluster"].values
        df_plot = df_plot.sort_values("Cluster")
        mat = df_plot.drop(columns=["Cluster"]).values

        fig_h = plt.figure(figsize=(10.0, 5.0))
        plt.imshow(mat, aspect="auto")
        plt.colorbar(label="z-score")
        plt.yticks([])
        plt.xticks(range(df_plot.shape[1] - 1), df_plot.drop(columns=["Cluster"]).columns, rotation=90, fontsize=7)
        plt.title("Top20 genes (z-score) sorted by Cluster")
        plt.tight_layout()
        st.pyplot(fig_h)
        artifact_put_fig_png("cluster_heatmap_top20.png", fig_h, note="Heatmap by cluster")
        plt.close(fig_h)
        st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("#### ç”Ÿå­˜åˆ†æï¼ˆæŒ‰ Cluster åˆ†ç»„ï¼‰")

    if not LIFELINES_OK:
        st.warning("æœªå®‰è£… lifelinesï¼špip install lifelines")
        st.markdown("</div>", unsafe_allow_html=True)
        return

    surv_df_source = read_csv_cached(surv_file) if surv_file is not None else st.session_state.get("cache_demo_surv_raw", None)
    if surv_df_source is None:
        st.info("æœªæä¾›ç”Ÿå­˜æ•°æ®ï¼ˆä¸Šä¼ æˆ–ç¤ºä¾‹ sur.csvï¼‰ï¼Œè·³è¿‡ KM/Coxã€‚")
        st.markdown("</div>", unsafe_allow_html=True)
        return

    surv = clean_columns(surv_df_source.copy())
    if "Sample" not in surv.columns:
        surv_cols = {_norm(c): c for c in surv.columns}
        for a in ["sample", "sampleid", "id", "subject", "patient"]:
            if _norm(a) in surv_cols:
                surv = surv.rename(columns={surv_cols[_norm(a)]: "Sample"})
                break

    if "Sample" not in surv.columns or "Time" not in surv.columns or "Event" not in surv.columns:
        st.error("ç”Ÿå­˜æ•°æ®å¿…é¡»åŒ…å«åˆ—ï¼šSample, Time, Event")
        st.markdown("</div>", unsafe_allow_html=True)
        return

    surv["Sample"] = surv["Sample"].astype(str).str.strip()
    surv = surv.set_index("Sample")

    cl = cluster_df.copy()
    cl["Sample"] = cl["Sample"].astype(str).str.strip()
    cl = cl.set_index("Sample")

    common = sorted(list(set(cl.index).intersection(set(surv.index))))
    if len(common) < 10:
        st.error("ç”Ÿå­˜æ•°æ®ä¸èšç±»æ ·æœ¬äº¤é›†å¤ªå°‘ï¼ˆ<10ï¼‰ï¼Œæ— æ³•ç”Ÿå­˜åˆ†æã€‚")
        st.markdown("</div>", unsafe_allow_html=True)
        return

    surv_aligned = surv.loc[common].copy()
    surv_aligned["Cluster"] = cl.loc[common]["Cluster"].astype(int).values
    surv_aligned["Time"] = pd.to_numeric(surv_aligned["Time"], errors="coerce")
    surv_aligned["Event"] = pd.to_numeric(surv_aligned["Event"], errors="coerce")
    surv_aligned = surv_aligned.dropna(subset=["Time", "Event", "Cluster"])

    fig_km, p_lr = km_plot_by_group(surv_aligned, group_col="Cluster")
    st.pyplot(fig_km)
    artifact_put_fig_png("survival_km_by_cluster.png", fig_km, note="KM curves by cluster")
    plt.close(fig_km)
    if p_lr is not None:
        st.write({"Log-rank p-value (2 groups)": p_lr})

    st.markdown("##### Coxï¼ˆCluster ä½œä¸ºåå˜é‡ï¼‰")
    df_cox = surv_aligned[["Time", "Event", "Cluster"]].copy().reset_index(drop=True)
    df_cox = pd.get_dummies(df_cox, columns=["Cluster"], drop_first=True)

    df_train, df_test = train_test_split(df_cox, test_size=float(test_size), random_state=int(seed_base))
    cph = CoxPHFitter(penalizer=float(cox_penalizer))
    cph.fit(df_train, duration_col="Time", event_col="Event")

    risk = cph.predict_partial_hazard(df_test)
    c_index = concordance_index(df_test["Time"], -risk.values, df_test["Event"])
    st.write({"C-index": float(c_index)})

    cox_sum = cph.summary.reset_index()
    st.session_state["cache_cox_cluster_summary"] = cox_sum
    artifact_put_df_csv("cox_cluster_summary.csv", cox_sum, note="Cox summary (Cluster)")
    st.dataframe(cox_sum, use_container_width=True, height=360)
    st.download_button("â¬‡ ä¸‹è½½ Cox summaryï¼ˆClusterï¼‰",
                       cox_sum.to_csv(index=False).encode("utf-8"),
                       "cox_cluster_summary.csv", mime="text/csv")
    st.markdown("</div>", unsafe_allow_html=True)


# =====================================================
# Dispatch
# =====================================================
page = st.session_state.get("page", "ä¸»æµç¨‹")
if page == "ä¸»æµç¨‹":
    render_main()
elif page == "ä¸‹è½½ä¸­å¿ƒ":
    render_download()
elif page == "åŠŸèƒ½å¯Œé›†":
    render_enrich()
elif page == "å·®å¼‚åˆ†æ":
    render_de()
elif page == "èšç±»&ç”Ÿå­˜":
    render_survival()

st.divider()
st.caption(
    "ä¾èµ–æç¤ºï¼šåŸºç¡€åŠŸèƒ½éœ€ streamlit/pandas/numpy/torch/scikit-learn/shap/matplotlibï¼›"
    "å·®å¼‚åˆ†æéœ€ scipy + statsmodelsï¼›"
    "GO/KEGGï¼ˆEnrichrï¼‰éœ€ gseapy ä¸”éœ€è¦ç½‘ç»œï¼›"
    "ç”Ÿå­˜åˆ†æéœ€ lifelinesã€‚"
)
