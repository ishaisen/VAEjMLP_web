# =====================================================
# app.py (PURE TABS + UI/UX POLISH 1~6 + Sticky Toolbar v2)
# VAEjMLP latent-SHAP + ç¨³å®šæ€§ + SHAPå¯è§†åŒ– + GO/KEGG + DE + èšç±» + ç”Ÿå­˜
#
# UI:
#   - Demo gateï¼ˆæœªå¼€å¯æ—¶ä»…æ˜¾ç¤ºå¼€å…³ï¼‰
#   - Hero ä¸‰åŒºå¡ç‰‡ï¼ˆInput/Workflow/Outputï¼‰
#   - ç»Ÿä¸€ card å¸ƒå±€ + KPI
#   - ä¸‹è½½ä¸­å¿ƒï¼šæ–‡ä»¶åˆ—è¡¨ + å•æ–‡ä»¶ä¸‹è½½ + ZIP + REPORT.md
#   - æ•°æ®è¾“å…¥å‹å¥½ï¼šåˆ—è¯†åˆ«æç¤ºã€å¯¹é½æç¤ºã€é¢„è§ˆä¸æ ¼å¼è¯´æ˜
#   - Sticky Toolbarï¼ˆå›ºå®šé¡¶éƒ¨ + é”šç‚¹è·³è½¬ + Tab é«˜äº® + å›åˆ°é¡¶éƒ¨ï¼‰
# =====================================================

import os
import io
import zipfile
from datetime import datetime

import streamlit as st
import streamlit.components.v1 as components

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
from sklearn.cluster import KMeans

import shap
import matplotlib.pyplot as plt

# ----------------- Optional deps -----------------
try:
    from scipy.stats import ttest_ind
    SCIPY_OK = True
except Exception:
    SCIPY_OK = False

try:
    from statsmodels.stats.multitest import multipletests
    STATSMODELS_OK = True
except Exception:
    STATSMODELS_OK = False

try:
    import gseapy as gp
    GSEAPY_OK = True
except Exception:
    GSEAPY_OK = False

try:
    from lifelines import CoxPHFitter, KaplanMeierFitter
    from lifelines.statistics import logrank_test
    from lifelines.utils import concordance_index
    LIFELINES_OK = True
except Exception:
    LIFELINES_OK = False


# =====================================================
# Demo files (HIDDEN)
# =====================================================
DEMO_DIR = "."
DEMO_RNA = "TCGA_GTEX_tmp.csv"
DEMO_LAB = "labels.csv"
DEMO_SUR = "sur.csv"


# =====================================================
# Utils
# =====================================================
def now_stamp():
    return datetime.now().strftime("%Y-%m-%d_%H%M%S")


def set_seed(seed: int):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


@st.cache_data(show_spinner=False)
def read_csv_cached(uploaded_file) -> pd.DataFrame:
    return pd.read_csv(uploaded_file)


@st.cache_data(show_spinner=False)
def read_csv_path_cached(path: str) -> pd.DataFrame:
    return pd.read_csv(path)


def to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8")


def fig_to_png_bytes(fig) -> bytes:
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=200, bbox_inches="tight")
    buf.seek(0)
    return buf.read()


def safe_rename_index_col(df: pd.DataFrame) -> pd.DataFrame:
    if "Unnamed: 0" in df.columns:
        df = df.rename(columns={"Unnamed: 0": "Gene"}).set_index("Gene")
    return df


def _norm(s: str) -> str:
    return str(s).strip().lower().replace(" ", "").replace("-", "").replace("_", "")


def clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).replace("\ufeff", "").strip() for c in df.columns]
    return df


def normalize_labels_df(labels_raw: pd.DataFrame):
    """
    è¿”å›ï¼š
      labels_df: æ ‡å‡†åŒ–åçš„ DataFrameï¼ˆSample/Labelï¼‰
      detect_info: dictï¼Œè®°å½•è¯†åˆ«å‡ºæ¥çš„åˆ—åä¿¡æ¯
    """
    labels = clean_columns(labels_raw.copy())
    if labels.shape[1] < 2:
        raise ValueError("Label æ–‡ä»¶è‡³å°‘éœ€è¦ä¸¤åˆ—ï¼ˆæ ·æœ¬åˆ— + æ ‡ç­¾åˆ—ï¼‰ã€‚")

    col_map = {_norm(c): c for c in labels.columns}
    sample_alias = ["sample", "sampleid", "sample_id", "id", "patient", "patientid", "subject", "subjectid"]
    label_alias = ["label", "group", "class", "y", "target", "phenotype", "status", "casecontrol", "case_control"]

    sample_col = None
    label_col = None
    for a in sample_alias:
        if _norm(a) in col_map:
            sample_col = col_map[_norm(a)]
            break
    for a in label_alias:
        if _norm(a) in col_map:
            label_col = col_map[_norm(a)]
            break

    fallback_sample = labels.columns[0]
    fallback_label = labels.columns[1] if labels.columns[1] != fallback_sample else labels.columns[0]

    if sample_col is None:
        sample_col = fallback_sample
    if label_col is None:
        label_col = fallback_label

    detect_info = {
        "raw_columns": list(labels.columns),
        "detected_sample_col": sample_col,
        "detected_label_col": label_col,
    }

    labels = labels.rename(columns={sample_col: "Sample", label_col: "Label"})
    labels["Sample"] = labels["Sample"].astype(str).str.strip()
    return labels[["Sample", "Label"]], detect_info


def align_rna_labels(rna_raw: pd.DataFrame, labels_raw: pd.DataFrame):
    """
    è¿”å›ï¼š
      rna_aligned, labels_aligned, align_info, label_detect_info
    """
    rna = safe_rename_index_col(rna_raw.copy())
    rna = clean_columns(rna)
    rna.columns = rna.columns.astype(str)

    labels, label_detect = normalize_labels_df(labels_raw)

    samples_rna = set(rna.columns.tolist())
    samples_lab = set(labels["Sample"].tolist())
    common = sorted(list(samples_rna.intersection(samples_lab)))

    if len(common) < 4:
        raise ValueError(f"RNA ä¸ Label äº¤é›†æ ·æœ¬æ•°å¤ªå°‘ï¼ˆ{len(common)}ï¼‰ï¼Œæ— æ³•è®­ç»ƒã€‚")

    align_info = {
        "rna_samples": len(samples_rna),
        "label_samples": len(samples_lab),
        "common_samples": len(common),
        "used_samples": len(common),
        "took_intersection": False,
    }

    if samples_rna != samples_lab:
        align_info["took_intersection"] = True
        rna = rna[common]
        labels = labels.set_index("Sample").loc[common].reset_index()

    labels = labels.set_index("Sample").loc[rna.columns].reset_index()
    labels = clean_columns(labels)

    return rna, labels, align_info, label_detect


def ensure_2d_shap(shap_values, features_2d: np.ndarray) -> np.ndarray:
    if isinstance(shap_values, list):
        shap_z = shap_values[0]
    else:
        shap_z = shap_values
    shap_z = np.array(shap_z)

    if shap_z.ndim == 3 and shap_z.shape[-1] == 1:
        shap_z = shap_z[:, :, 0]
    if shap_z.ndim == 3 and shap_z.shape[0] == 1:
        shap_z = shap_z[0]

    if shap_z.ndim != 2:
        raise ValueError(f"Unexpected SHAP shape: {shap_z.shape}")

    if shap_z.shape[0] != features_2d.shape[0] or shap_z.shape[1] != features_2d.shape[1]:
        raise ValueError(f"Shape mismatch: shap={shap_z.shape}, features={features_2d.shape}")

    return shap_z


def compute_de_top_genes(rna: pd.DataFrame, labels: pd.DataFrame, top_genes: list):
    if not SCIPY_OK:
        raise RuntimeError("ç¼ºå°‘ scipyï¼Œæ— æ³•åš t-testã€‚è¯·å®‰è£…ï¼špip install scipy")
    if not STATSMODELS_OK:
        raise RuntimeError("ç¼ºå°‘ statsmodelsï¼Œæ— æ³•åš FDRã€‚è¯·å®‰è£…ï¼špip install statsmodels")

    rna = clean_columns(rna.copy())
    rna.columns = rna.columns.astype(str)

    lab = clean_columns(labels.copy())
    if ("Sample" not in lab.columns) or ("Label" not in lab.columns):
        lab, _ = normalize_labels_df(lab)
    else:
        lab["Sample"] = lab["Sample"].astype(str).str.strip()

    lab2 = lab.set_index("Sample").reindex(rna.columns)

    missing = lab2.index[lab2["Label"].isna()].tolist()
    if len(missing) > 0:
        raise ValueError(f"labels ä¸­ç¼ºå°‘ {len(missing)} ä¸ªæ ·æœ¬çš„æ ‡ç­¾ï¼ˆç¤ºä¾‹å‰5ä¸ªï¼‰ï¼š{missing[:5]}")

    groups = pd.Series(lab2["Label"].values).unique().tolist()
    if len(groups) != 2:
        raise ValueError(f"å·®å¼‚åˆ†æéœ€è¦ä¸¤ç»„ Labelï¼Œç›®å‰å‘ç° {len(groups)} ç»„ï¼š{groups}")

    g0, g1 = groups[0], groups[1]
    s0 = lab2[lab2["Label"] == g0].index.tolist()
    s1 = lab2[lab2["Label"] == g1].index.tolist()

    if len(s0) < 2 or len(s1) < 2:
        raise ValueError(f"ä¸¤ç»„æ ·æœ¬æ•°ä¸è¶³ï¼š{g0}={len(s0)}, {g1}={len(s1)}ï¼ˆæ¯ç»„è‡³å°‘ 2ï¼‰")

    eps = 1e-9
    rows = []
    for gene in top_genes:
        if gene not in rna.index:
            continue
        x0 = rna.loc[gene].reindex(s0).astype(float).values
        x1 = rna.loc[gene].reindex(s1).astype(float).values

        _, p = ttest_ind(x1, x0, equal_var=False, nan_policy="omit")
        m0 = np.nanmean(x0)
        m1 = np.nanmean(x1)
        log2fc = np.log2((m1 + eps) / (m0 + eps))
        rows.append([gene, m0, m1, log2fc, p])

    de = pd.DataFrame(rows, columns=["Gene", f"Mean({g0})", f"Mean({g1})", "log2FC", "p_value"])
    if len(de) == 0:
        raise ValueError("Top genes åœ¨ RNA ä¸­æœªåŒ¹é…åˆ°ä»»ä½•åŸºå› ã€‚")

    de["FDR"] = multipletests(de["p_value"].values, method="fdr_bh")[1]
    de = de.sort_values(["FDR", "p_value"], ascending=True).reset_index(drop=True)
    return de, (g0, g1)


def run_enrichr(top_genes: list, organism: str = "Human"):
    if not GSEAPY_OK:
        raise RuntimeError("ç¼ºå°‘ gseapyï¼Œæ— æ³•åš GO/KEGGã€‚è¯·å®‰è£…ï¼špip install gseapy")

    if organism.lower().startswith("h"):
        libs = [
            "GO_Biological_Process_2021",
            "GO_Molecular_Function_2021",
            "GO_Cellular_Component_2021",
            "KEGG_2021_Human",
        ]
    else:
        libs = [
            "GO_Biological_Process_2021",
            "GO_Molecular_Function_2021",
            "GO_Cellular_Component_2021",
            "KEGG_2021_Mouse",
        ]

    out = {}
    for lib in libs:
        enr = gp.enrichr(gene_list=top_genes, gene_sets=lib, organism=organism, outdir=None)
        out[lib] = enr.results.copy()
    return out


def cluster_samples_by_top_genes(rna: pd.DataFrame, top_genes: list, n_clusters: int = 2, seed: int = 42):
    rna = clean_columns(rna.copy())
    rna.columns = rna.columns.astype(str)

    genes_exist = [g for g in top_genes if g in rna.index]
    if len(genes_exist) < 2:
        raise ValueError("Top genes åœ¨ RNA ä¸­åŒ¹é…åˆ°çš„åŸºå› å¤ªå°‘ï¼ˆ<2ï¼‰ï¼Œæ— æ³•èšç±»ã€‚")

    X = rna.loc[genes_exist].T.astype(float)
    X_scaled = StandardScaler().fit_transform(X.values)

    km = KMeans(n_clusters=int(n_clusters), random_state=int(seed), n_init="auto")
    clusters = km.fit_predict(X_scaled)

    cluster_df = pd.DataFrame({"Sample": X.index.astype(str), "Cluster": clusters.astype(int)})
    X_scaled_df = pd.DataFrame(X_scaled, index=X.index.astype(str), columns=genes_exist)
    return cluster_df, X_scaled_df


def km_plot_by_group(surv_df: pd.DataFrame, group_col: str, time_col: str = "Time", event_col: str = "Event"):
    if not LIFELINES_OK:
        raise RuntimeError("ç¼ºå°‘ lifelinesï¼Œæ— æ³•åš KM/Coxã€‚è¯·å®‰è£…ï¼špip install lifelines")

    fig = plt.figure(figsize=(7.8, 4.6))
    kmf = KaplanMeierFitter()
    groups = sorted(surv_df[group_col].unique().tolist())

    for g in groups:
        dfg = surv_df[surv_df[group_col] == g]
        kmf.fit(durations=dfg[time_col], event_observed=dfg[event_col], label=f"{group_col}={g} (n={len(dfg)})")
        kmf.plot(ci_show=False)

    plt.title("Kaplan-Meier")
    plt.xlabel("Time")
    plt.ylabel("Survival probability")
    plt.tight_layout()

    p_lr = None
    if len(groups) == 2:
        g0, g1 = groups
        df0 = surv_df[surv_df[group_col] == g0]
        df1 = surv_df[surv_df[group_col] == g1]
        lr = logrank_test(
            df0[time_col], df1[time_col],
            event_observed_A=df0[event_col],
            event_observed_B=df1[event_col],
        )
        p_lr = float(lr.p_value)

    return fig, p_lr


# =====================================================
# Artifact manager (Downloads center)
# =====================================================
def artifacts_init():
    if "cache_artifacts" not in st.session_state:
        st.session_state["cache_artifacts"] = {}  # name -> dict(bytes, mime, kind, note)
    if "cache_fig_pngs" not in st.session_state:
        st.session_state["cache_fig_pngs"] = {}


def artifact_put_bytes(name: str, b: bytes, mime: str, kind: str = "file", note: str = ""):
    artifacts_init()
    st.session_state["cache_artifacts"][name] = {"bytes": b, "mime": mime, "kind": kind, "note": note}


def artifact_put_df_csv(name: str, df: pd.DataFrame, note: str = ""):
    artifact_put_bytes(name, to_csv_bytes(df), "text/csv", kind="csv", note=note)


def artifact_put_fig_png(name: str, fig, note: str = ""):
    b = fig_to_png_bytes(fig)
    artifact_put_bytes(name, b, "image/png", kind="png", note=note)
    st.session_state["cache_fig_pngs"][name] = b


def build_report_md() -> str:
    src = st.session_state.get("cache_data_source", "unknown")
    at = st.session_state.get("cache_cached_at", "")
    params = st.session_state.get("cache_params", {})
    top20 = st.session_state.get("cache_top20_genes", [])
    summary_df = st.session_state.get("cache_summary_df", None)

    md = []
    md.append("# VAEjMLP latent-SHAP Results Report\n")
    md.append(f"- Generated at: **{datetime.now().isoformat(timespec='seconds')}**\n")
    md.append(f"- Cached at: **{at}**\n")
    md.append(f"- Data source: **{src}**\n\n")

    md.append("## Parameters\n")
    if params:
        for k, v in params.items():
            md.append(f"- {k}: {v}\n")
    else:
        md.append("- (no params captured)\n")
    md.append("\n")

    md.append("## Metrics Summary (mean Â± std)\n")
    if isinstance(summary_df, pd.DataFrame):
        md.append(summary_df.to_markdown(index=False))
        md.append("\n\n")
    else:
        md.append("- (no summary)\n\n")

    md.append("## Top 20 Biomarkers\n")
    if top20:
        for g in top20:
            md.append(f"- {g}\n")
    else:
        md.append("- (no top20)\n")

    md.append("\n## Notes\n")
    md.append("- ZIP bundle includes CSV/PNG produced in current session.\n")
    md.append("- GO/KEGG requires gseapy and network access to Enrichr.\n")
    md.append("- DE requires scipy + statsmodels.\n")
    md.append("- Survival requires lifelines.\n")

    return "".join(md)


def build_results_zip(ts: str) -> bytes:
    artifacts_init()
    zbuf = io.BytesIO()
    with zipfile.ZipFile(zbuf, "w", zipfile.ZIP_DEFLATED) as zf:
        for name, meta in st.session_state["cache_artifacts"].items():
            zf.writestr(name, meta["bytes"])

        zf.writestr("REPORT.md", build_report_md().encode("utf-8"))

        meta = {
            "generated_at": datetime.now().isoformat(timespec="seconds"),
            "data_source": st.session_state.get("cache_data_source", "unknown"),
            "cached_at": st.session_state.get("cache_cached_at", ""),
            "bundle_ts": ts,
            "artifact_count": len(st.session_state["cache_artifacts"]),
        }
        zf.writestr("README_metadata.json", pd.Series(meta).to_json())

    zbuf.seek(0)
    return zbuf.read()


def artifact_table_df():
    artifacts_init()
    rows = []
    for name, meta in st.session_state["cache_artifacts"].items():
        size_kb = len(meta["bytes"]) / 1024.0
        rows.append([name, meta.get("kind", ""), meta.get("mime", ""), f"{size_kb:.1f} KB", meta.get("note", "")])
    if not rows:
        return pd.DataFrame(columns=["File", "Type", "MIME", "Size", "Note"])
    return pd.DataFrame(rows, columns=["File", "Type", "MIME", "Size", "Note"]).sort_values("Type")


# =====================================================
# Model
# =====================================================
class VAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, latent_dim * 2)

    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        h2 = F.relu(self.fc2(h1))
        h3 = self.fc3(h2)
        mean, log_var = torch.chunk(h3, 2, dim=-1)
        return mean, log_var

    def reparameterize(self, mean, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mean + eps * std

    def forward(self, x):
        mean, log_var = self.encode(x)
        z = self.reparameterize(mean, log_var)
        return z, mean, log_var


class MLP(nn.Module):
    def __init__(self, latent_dim):
        super().__init__()
        self.fc1 = nn.Linear(latent_dim, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 1)

    def forward(self, z):
        z = F.relu(self.fc1(z))
        z = F.relu(self.fc2(z))
        return torch.sigmoid(self.fc3(z))


# =====================================================
# Sticky Toolbar (v2: Active highlight + Back to top)
# =====================================================
def render_sticky_toolbar():
    run_ok = "cache_stability_df" in st.session_state
    data_source = st.session_state.get("cache_data_source", "æœªè¿è¡Œ")
    cached_at = st.session_state.get("cache_cached_at", "")

    status_badge = "âœ… å·²è¿è¡Œ" if run_ok else "âš ï¸ æœªè¿è¡Œ"
    status_color = "#16A34A" if run_ok else "#F59E0B"

    html = f"""
    <style>
      .block-container {{ padding-top: 5.8rem; }}

      .stickybar {{
        position: fixed;
        top: 0; left: 0; right: 0;
        z-index: 9999;
        background: rgba(255,255,255,0.86);
        backdrop-filter: blur(10px);
        border-bottom: 1px solid rgba(15,23,42,0.10);
      }}
      .sticky-inner {{
        max-width: 1400px;
        margin: 0 auto;
        padding: 10px 18px;
        display: flex;
        align-items: center;
        justify-content: space-between;
        gap: 14px;
        font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      }}
      .left {{
        display: flex;
        align-items: center;
        gap: 10px;
        min-width: 320px;
        flex-wrap: wrap;
      }}
      .brand {{
        font-weight: 800;
        letter-spacing: -0.02em;
        color: #0F172A;
        font-size: 14px;
        white-space: nowrap;
      }}
      .badge {{
        display: inline-flex;
        align-items: center;
        gap: 6px;
        padding: 6px 10px;
        border-radius: 999px;
        border: 1px solid rgba(15,23,42,0.12);
        background: rgba(255,255,255,0.70);
        font-size: 12px;
        white-space: nowrap;
      }}
      .dot {{
        width: 8px; height: 8px;
        border-radius: 999px;
        background: {status_color};
        display: inline-block;
      }}
      .right {{
        display: flex;
        align-items: center;
        gap: 8px;
        flex-wrap: wrap;
        justify-content: flex-end;
      }}
      .btn {{
        display: inline-flex;
        align-items: center;
        gap: 8px;
        padding: 8px 10px;
        border-radius: 10px;
        border: 1px solid rgba(15,23,42,0.12);
        background: rgba(255,255,255,0.70);
        color: #0F172A;
        text-decoration: none;
        font-size: 12px;
        cursor: pointer;
        transition: all .12s ease;
        user-select: none;
      }}
      .btn:hover {{
        background: rgba(246,248,252,0.95);
        transform: translateY(-1px);
      }}
      .btn.primary {{
        border-color: rgba(46,125,255,0.35);
        background: rgba(46,125,255,0.10);
      }}
      .btn.active {{
        border-color: rgba(46,125,255,0.55);
        background: rgba(46,125,255,0.18);
        box-shadow: 0 1px 10px rgba(46,125,255,0.10);
      }}
      .muted {{
        opacity: 0.65;
        font-size: 12px;
        white-space: nowrap;
      }}
      .sep {{
        width: 1px; height: 20px;
        background: rgba(15,23,42,0.10);
        margin: 0 4px;
      }}
    </style>

    <div class="stickybar">
      <div class="sticky-inner">
        <div class="left">
          <div class="brand">ğŸ§¬ VAEjMLP BioApp</div>
          <div class="badge"><span class="dot"></span>{status_badge}</div>
          <div class="badge">æ•°æ®æºï¼š{data_source}</div>
          <div class="badge">ç¼“å­˜ï¼š{cached_at if cached_at else "â€”"}</div>
        </div>

        <div class="right">
          <a class="btn primary" href="#run">ğŸš€ è¿è¡ŒåŒº</a>
          <div class="sep"></div>
          <a class="btn nav" id="nav-main" href="#main">â‘  ä¸»æµç¨‹</a>
          <a class="btn nav" id="nav-download" href="#download">â‘¡ ä¸‹è½½</a>
          <a class="btn nav" id="nav-enrich" href="#enrich">â‘¢ å¯Œé›†</a>
          <a class="btn nav" id="nav-de" href="#de">â‘£ å·®å¼‚</a>
          <a class="btn nav" id="nav-survival" href="#survival">â‘¤ ç”Ÿå­˜</a>
          <div class="sep"></div>
          <a class="btn" href="#top">â¬† å›åˆ°é¡¶éƒ¨</a>
          <span class="muted">æ»šåŠ¨åˆ°æ¨¡å—ä¼šé«˜äº®</span>
        </div>
      </div>
    </div>

    <script>
      const sections = [
        ["main", "nav-main"],
        ["download", "nav-download"],
        ["enrich", "nav-enrich"],
        ["de", "nav-de"],
        ["survival", "nav-survival"],
      ];

      function setActive(btnId) {{
        sections.forEach(([sec, id]) => {{
          const el = document.getElementById(id);
          if (el) el.classList.remove("active");
        }});
        const active = document.getElementById(btnId);
        if (active) active.classList.add("active");
      }}

      sections.forEach(([secId, btnId]) => {{
        const target = document.getElementById(secId);
        if (!target) return;

        const obs = new IntersectionObserver((entries) => {{
          entries.forEach(entry => {{
            if (entry.isIntersecting) {{
              setActive(btnId);
            }}
          }});
        }}, {{
          root: null,
          threshold: 0.01,
          rootMargin: "-35% 0px -60% 0px"
        }});

        obs.observe(target);
      }});

      setActive("nav-main");
    </script>
    """
    components.html(html, height=0)


# =====================================================
# Page + Styles
# =====================================================
st.set_page_config(page_title="VAEjMLP latent-SHAP BioApp", layout="wide")

# ---- Anchors: top ----
st.markdown('<div id="top"></div>', unsafe_allow_html=True)

# ---- Sticky toolbar FIRST ----
render_sticky_toolbar()

st.markdown(
    """
    <style>
      .block-container { padding-bottom: 2rem; max-width: 1400px; }
      h1, h2, h3 { letter-spacing: -0.01em; }

      .heroWrap {
        border: 1px solid rgba(49,51,63,0.10);
        border-radius: 18px;
        padding: 18px 18px 8px 18px;
        background: linear-gradient(180deg, rgba(255,255,255,0.80), rgba(255,255,255,0.50));
        box-shadow: 0 1px 16px rgba(0,0,0,0.03);
        margin-bottom: 14px;
      }
      .heroTitle { font-size: 20px; font-weight: 800; margin: 0 0 6px 0; }
      .heroSub { opacity: 0.75; margin: 0 0 12px 0; }

      .card {
        border: 1px solid rgba(49,51,63,0.12);
        border-radius: 16px;
        padding: 14px 14px;
        background: rgba(255,255,255,0.66);
        backdrop-filter: blur(6px);
        box-shadow: 0 1px 10px rgba(0,0,0,0.02);
        margin-bottom: 14px;
      }

      .kpi {
        border: 1px solid rgba(49,51,63,0.15);
        border-radius: 14px;
        padding: 14px 16px;
        background: rgba(255,255,255,0.6);
        backdrop-filter: blur(6px);
        box-shadow: 0 1px 10px rgba(0,0,0,0.03);
      }
      .kpi .label { font-size: 0.85rem; opacity: 0.7; }
      .kpi .value { font-size: 1.3rem; font-weight: 800; margin-top: 2px; }
      .kpi .hint  { font-size: 0.8rem; opacity: 0.55; margin-top: 6px; }

      .badge {
        display: inline-block;
        padding: 6px 10px;
        border-radius: 999px;
        border: 1px solid rgba(49,51,63,0.15);
        background: rgba(255,255,255,0.65);
        font-size: 12px;
        margin-left: 6px;
      }
      .badge.good { border-color: rgba(0, 128, 0, 0.25); }
      .badge.warn { border-color: rgba(255, 165, 0, 0.35); }

      .smallMuted { opacity: 0.70; font-size: 0.90rem; }
      .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }

      .stDataFrame { border-radius: 12px; overflow: hidden; }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ§¬ VAEjMLP + latent SHAP ç”Ÿç‰©æ ‡å¿—ç‰©åˆ†æå¹³å°")
st.caption("Latent è¡¨å¾å­¦ä¹  â†’ è§£é‡Šæ€§ï¼ˆSHAPï¼‰â†’ ç¨³å®šæ€§è¯„ä¼° â†’ åŠŸèƒ½å¯Œé›† â†’ å·®å¼‚åˆ†æ â†’ èšç±»ä¸ç”Ÿå­˜éªŒè¯")

artifacts_init()

# =====================================================
# Gate: only demo switch visible until enabled
# =====================================================
with st.sidebar:
    st.header("ç¤ºä¾‹æ•°æ®")
    use_demo_gate = st.checkbox("ä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆDemoï¼‰", value=False)
    if not use_demo_gate:
        st.info("å½“å‰ä»…æ˜¾ç¤ºæ­¤å¼€å…³ã€‚æ‰“å¼€åæ‰æ˜¾ç¤ºå®Œæ•´åŠŸèƒ½ä¸å‚æ•°ã€‚")

if not use_demo_gate:
    st.markdown(
        """
        <div class="card">
          <div class="heroTitle">æ•´ä½“å·¥ä½œä»‹ç»</div>
          <div class="smallMuted">
            æœ¬å·¥å…·é¢å‘ RNA-seq è¡¨è¾¾çŸ©é˜µï¼ˆgenesÃ—samplesï¼‰ä¸äºŒåˆ†ç±»æ ‡ç­¾ï¼Œè®­ç»ƒ <b>VAE + MLP</b> å­¦ä¹  latent è¡¨å¾ï¼›
            ä½¿ç”¨ <b>latent SHAP</b> è§£é‡Šæ¨¡å‹å†³ç­–å¹¶æ˜ å°„å›åŸºå› å±‚å½¢æˆå€™é€‰ biomarkersï¼›
            æ”¯æŒå¤šæ¬¡è¿è¡Œåšç¨³å®šæ€§è¯„ä¼°ï¼ˆé¢‘ç‡/CVï¼‰ï¼›å¹¶å¯¹ Top20 åšå¯Œé›†ã€å·®å¼‚ã€èšç±»åŠç”Ÿå­˜éªŒè¯ã€‚
          </div>
          <ul class="smallMuted" style="margin-top:10px;">
            <li><b>è¾“å…¥</b>ï¼šRNAã€labelsï¼ˆSample/Labelï¼‰ã€ï¼ˆå¯é€‰ï¼‰survivalï¼ˆSample/Time/Eventï¼‰</li>
            <li><b>è¾“å‡º</b>ï¼šæ€§èƒ½æŒ‡æ ‡ã€Top biomarkersã€ç¨³å®šæ€§ã€SHAPã€å¯Œé›†/å·®å¼‚/èšç±»/ç”Ÿå­˜ã€ä¸‹è½½</li>
          </ul>
          <div class="smallMuted">ğŸ‘‰ è¯·åœ¨å·¦ä¾§æ‰“å¼€ã€Œä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆDemoï¼‰ã€è¿›å…¥å®Œæ•´é¡µé¢ã€‚</div>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.stop()

# =====================================================
# Sidebar: parameters only
# =====================================================
with st.sidebar:
    st.divider()
    st.header("ä¸»æµç¨‹å‚æ•°")

    latent_dim = st.number_input("latent_dim", min_value=4, max_value=1024, value=128, step=4)
    n_epochs = st.number_input("è®­ç»ƒè½®æ•° epochs", min_value=10, max_value=2000, value=100, step=10)
    lr = st.number_input("å­¦ä¹ ç‡ lr", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-4, format="%.5f")
    ce_weight = st.number_input("CE æƒé‡ï¼ˆloss = KL + ce_weight*CEï¼‰", min_value=0.0, max_value=10.0, value=0.001, step=0.001)
    test_size = st.slider("test_size", 0.05, 0.5, 0.2, 0.05)

    st.subheader("ç¨³å®šæ€§ (multi-run)")
    n_runs = st.slider("é‡å¤è¿è¡Œæ¬¡æ•° n_runs", 1, 50, 10)
    top_k = st.slider("TopK é¢‘ç‡ç»Ÿè®¡", 5, 300, 20)
    seed_base = st.number_input("seed_base", value=42, step=1)

    st.subheader("SHAP è®¡ç®—")
    background_n = st.slider("background æ ·æœ¬æ•°", 10, 200, 50)
    shap_nsamples = st.slider("KernelExplainer nsamples", 50, 500, 100, 50)

    st.divider()
    st.header("èšç±»/ç”Ÿå­˜å‚æ•°")
    cluster_k = st.slider("èšç±»ç°‡æ•° K", 2, 6, 2)
    cox_penalizer = st.number_input("Cox L2 penalizer", min_value=0.0, max_value=10.0, value=0.1, step=0.1)

# =====================================================
# Param help popover/expander
# =====================================================
def render_param_help():
    rows = [
        ["latent_dim", "VAE latent ç©ºé—´ç»´åº¦", "æ›´å¤§â†’è¡¨è¾¾æ›´å¼ºä½†æ›´æ…¢/æ›´æ˜“è¿‡æ‹Ÿåˆï¼›å¸¸ç”¨ 32/64/128"],
        ["epochs", "è®­ç»ƒè½®æ•°", "è¶Šå¤§è¶Šå……åˆ†ï¼›è¿‡å¤§å¯èƒ½è¿‡æ‹Ÿåˆã€è€—æ—¶å¢åŠ "],
        ["lr", "å­¦ä¹ ç‡", "å¤ªå¤§ä¸æ”¶æ•›ï¼Œå¤ªå°æ”¶æ•›æ…¢ï¼›å¸¸ç”¨ 1e-3~1e-4"],
        ["ce_weight", "åˆ†ç±»æŸå¤±æƒé‡", "loss = KL + ce_weight * CEï¼›è¶Šå¤§è¶Šå¼ºè°ƒåˆ†ç±»"],
        ["test_size", "æµ‹è¯•é›†æ¯”ä¾‹", "0.2 å¸¸ç”¨ï¼›æ ·æœ¬å°‘æ—¶åˆ«å¤ªå¤§"],
        ["n_runs", "é‡å¤è¿è¡Œæ¬¡æ•°", "ç”¨äºç¨³å®šæ€§è¯„ä¼°ï¼›è¶Šå¤§è¶Šç¨³ä½†æ›´æ…¢"],
        ["top_k", "TopK é¢‘ç‡ç»Ÿè®¡", "æ¯æ¬¡ run å–å‰ K ä¸ªåŸºå› ï¼Œç»Ÿè®¡å‡ºç°é¢‘ç‡"],
        ["seed_base", "éšæœºç§å­åŸºæ•°", "Run i çš„ seed = seed_base + i"],
        ["background_n", "SHAP èƒŒæ™¯æ ·æœ¬æ•°", "è¶Šå¤§è¶Šå‡†ä½†è¶Šæ…¢"],
        ["shap_nsamples", "SHAP é‡‡æ ·æ•°", "è¶Šå¤§è¶Šå‡†ä½†è¶Šæ…¢"],
        ["cluster_k", "èšç±»ç°‡æ•°", "Top20 è¡¨è¾¾åš KMeans çš„ K"],
        ["cox_penalizer", "Cox æ­£åˆ™å¼ºåº¦", "è¶Šå¤§â†’æ›´å¼º L2 æ­£åˆ™ï¼Œå‡å°‘ä¸ç¨³å®š"],
    ]
    st.dataframe(pd.DataFrame(rows, columns=["å‚æ•°", "å«ä¹‰", "å»ºè®®/å½±å“"]), use_container_width=True)

try:
    with st.popover("ğŸ“˜ å‚æ•°è¯´æ˜"):
        render_param_help()
except Exception:
    with st.expander("ğŸ“˜ å‚æ•°è¯´æ˜", expanded=False):
        render_param_help()

# =====================================================
# Hero cards
# =====================================================
st.markdown('<div class="heroWrap">', unsafe_allow_html=True)
st.markdown('<div class="heroTitle">ä¸€ç«™å¼ Biomarker å‘ç°ä¸éªŒè¯</div>', unsafe_allow_html=True)
st.markdown('<div class="heroSub">ä»è¡¨è¾¾çŸ©é˜µåˆ°å¯è§£é‡Šæ€§ã€ç¨³å®šæ€§ä¸éªŒè¯åˆ†æï¼ˆå¯Œé›†/å·®å¼‚/èšç±»/ç”Ÿå­˜ï¼‰</div>', unsafe_allow_html=True)

hc1, hc2, hc3 = st.columns(3)
with hc1:
    st.markdown(
        """
        <div class="card">
          <b>Input</b>
          <div class="smallMuted" style="margin-top:8px;">
            <ul>
              <li>RNA: genes Ã— samplesï¼ˆCSVï¼‰</li>
              <li>Labels: Sample / Labelï¼ˆCSVï¼‰</li>
              <li>Survival: Sample / Time / Eventï¼ˆå¯é€‰ï¼‰</li>
            </ul>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
with hc2:
    st.markdown(
        """
        <div class="card">
          <b>Workflow</b>
          <div class="smallMuted" style="margin-top:8px;">
            VAE å‹ç¼© â†’ MLP åˆ†ç±» â†’ latent SHAP â†’ æ˜ å°„å›åŸºå›  â†’ å¤šæ¬¡è¿è¡Œç¨³å®šæ€§
          </div>
          <div class="smallMuted" style="margin-top:10px;">
            ä¸‹æ¸¸ï¼šGO/KEGGã€å·®å¼‚åˆ†æã€Top20 èšç±»ã€ç”Ÿå­˜éªŒè¯
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )
with hc3:
    st.markdown(
        """
        <div class="card">
          <b>Output</b>
          <div class="smallMuted" style="margin-top:8px;">
            <ul>
              <li>æ€§èƒ½æŒ‡æ ‡ï¼ˆAUC/Acc/Prec/Recallï¼‰</li>
              <li>Top biomarkers + ç¨³å®šæ€§ï¼ˆFreq/CVï¼‰</li>
              <li>SHAP å›¾ã€å¯Œé›†/å·®å¼‚/èšç±»/ç”Ÿå­˜</li>
              <li>CSV/PNG/ZIP + REPORT.md</li>
            </ul>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )

st.markdown("</div>", unsafe_allow_html=True)

# =====================================================
# Tools
# =====================================================
tools_left, tools_right = st.columns([1, 2])
with tools_left:
    if st.button("ğŸ§¹ æ¸…ç©ºç¼“å­˜ç»“æœï¼ˆä¸æ¸…ç©ºä¸Šä¼ ï¼‰"):
        for k in list(st.session_state.keys()):
            if k.startswith("cache_") or k == "cache_demo_surv_raw":
                st.session_state.pop(k, None)
        artifacts_init()
        st.success("å·²æ¸…ç©ºç¼“å­˜ç»“æœã€‚")
        st.rerun()
with tools_right:
    st.markdown(
        """
        <div class="smallMuted">
        æç¤ºï¼šç¤ºä¾‹æ•°æ®å¯ä¸€é”®è·‘é€šå…¨æµç¨‹ï¼›è‹¥ç”¨ä¸Šä¼ æ•°æ®ï¼Œè¯·ç¡®ä¿ RNA åˆ—åï¼ˆæ ·æœ¬åï¼‰èƒ½ä¸ labels çš„ Sample å¯¹é½ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

# =====================================================
# Uploaders + RUN (Anchor: run)
# =====================================================
st.markdown('<div id="run"></div>', unsafe_allow_html=True)

st.markdown('<div class="card">', unsafe_allow_html=True)
st.markdown("### æ•°æ®è¾“å…¥")
u1, u2, u3 = st.columns(3)
with u1:
    rna_file = st.file_uploader("RNA-seqï¼ˆgenesÃ—samplesï¼‰CSVï¼ˆå¯é€‰ï¼‰", type="csv", key="rna_uploader")
with u2:
    label_file = st.file_uploader("Labels CSVï¼ˆSample/Labelï¼Œå¯é€‰ï¼‰", type="csv", key="label_uploader")
with u3:
    surv_file = st.file_uploader("Survival CSVï¼ˆSample,Time,Eventï¼Œå¯é€‰ï¼‰", type="csv", key="surv_uploader")

use_demo_data = st.checkbox("æœ¬æ¬¡è¿è¡Œä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆå¿½ç•¥ä¸Šä¼ ï¼‰", value=True)

with st.expander("ğŸ“ æ•°æ®æ ¼å¼ç¤ºä¾‹ / é¢„è§ˆï¼ˆå»ºè®®å…ˆçœ‹ï¼‰", expanded=False):
    st.markdown("**RNA (genesÃ—samples) ç¤ºä¾‹ï¼š**")
    st.dataframe(
        pd.DataFrame({"Gene": ["TP53", "EGFR", "BRCA1"], "S1": [3.2, 0.1, 1.7], "S2": [2.9, 0.2, 1.4]}).set_index("Gene"),
        use_container_width=True,
    )
    st.markdown("**Labels ç¤ºä¾‹ï¼š**")
    st.dataframe(pd.DataFrame({"Sample": ["S1", "S2"], "Label": [0, 1]}), use_container_width=True)
    st.markdown("**Survival ç¤ºä¾‹ï¼š**")
    st.dataframe(pd.DataFrame({"Sample": ["S1", "S2"], "Time": [120, 340], "Event": [1, 0]}), use_container_width=True)

    if (not use_demo_data) and (rna_file is not None) and (label_file is not None):
        try:
            st.markdown("**ä½ ä¸Šä¼ çš„ RNA å‰ 5 è¡Œï¼š**")
            st.dataframe(read_csv_cached(rna_file).head(5), use_container_width=True)
            st.markdown("**ä½ ä¸Šä¼ çš„ Labels å‰ 5 è¡Œï¼š**")
            st.dataframe(read_csv_cached(label_file).head(5), use_container_width=True)
        except Exception as e:
            st.warning(f"é¢„è§ˆå¤±è´¥ï¼š{e}")

run_button = st.button("ğŸš€ è¿è¡Œä¸»æµç¨‹", type="primary")
st.markdown("</div>", unsafe_allow_html=True)

# =====================================================
# Main pipeline
# =====================================================
if run_button:
    st.session_state["cache_params"] = {
        "latent_dim": int(latent_dim),
        "epochs": int(n_epochs),
        "lr": float(lr),
        "ce_weight": float(ce_weight),
        "test_size": float(test_size),
        "n_runs": int(n_runs),
        "top_k": int(top_k),
        "seed_base": int(seed_base),
        "background_n": int(background_n),
        "shap_nsamples": int(shap_nsamples),
        "cluster_k": int(cluster_k),
        "cox_penalizer": float(cox_penalizer),
    }

    if use_demo_data:
        rna_path = os.path.join(DEMO_DIR, DEMO_RNA)
        lab_path = os.path.join(DEMO_DIR, DEMO_LAB)
        sur_path = os.path.join(DEMO_DIR, DEMO_SUR)

        if (not os.path.exists(rna_path)) or (not os.path.exists(lab_path)):
            st.error(
                "ç¤ºä¾‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ã€‚è¯·æŠŠç¤ºä¾‹æ–‡ä»¶æ”¾åœ¨ app.py åŒç›®å½•ï¼š\n"
                f"- {rna_path}\n- {lab_path}\n- {sur_path}ï¼ˆå¯é€‰ï¼‰"
            )
            st.stop()

        with st.spinner("è¯»å–ç¤ºä¾‹æ•°æ®ä¸­..."):
            rna_raw = read_csv_path_cached(rna_path)
            labels_raw = read_csv_path_cached(lab_path)

        if os.path.exists(sur_path):
            st.session_state["cache_demo_surv_raw"] = read_csv_path_cached(sur_path)
        else:
            st.session_state["cache_demo_surv_raw"] = None

        st.session_state["cache_data_source"] = "Demo"
    else:
        st.session_state["cache_demo_surv_raw"] = None
        if rna_file is None or label_file is None:
            st.error("æœªé€‰æ‹©ç¤ºä¾‹æ•°æ®æ—¶ï¼Œå¿…é¡»ä¸Šä¼  RNA ä¸ Labelã€‚")
            st.stop()

        with st.spinner("è¯»å–ä¸Šä¼ æ•°æ®ä¸­..."):
            rna_raw = read_csv_cached(rna_file)
            labels_raw = read_csv_cached(label_file)

        st.session_state["cache_data_source"] = "Upload"

    with st.spinner("å¯¹é½æ ·æœ¬ä¸åˆ—è¯†åˆ«ä¸­..."):
        try:
            rna, labels, align_info, label_detect = align_rna_labels(rna_raw, labels_raw)
        except Exception as e:
            st.error(f"æ•°æ®å¯¹é½å¤±è´¥ï¼š{e}")
            st.stop()

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### âœ… è¾“å…¥æ£€æŸ¥ä¸å¯¹é½ä¿¡æ¯")
    st.write({
        "Label åˆ—è¯†åˆ«": label_detect,
        "æ ·æœ¬å¯¹é½": align_info,
        "å¯¹é½å RNA ç»´åº¦ (genesÃ—samples)": f"{rna.shape[0]} Ã— {rna.shape[1]}",
    })
    if align_info.get("took_intersection", False):
        st.warning("RNA ä¸ Labels æ ·æœ¬ä¸å®Œå…¨ä¸€è‡´ï¼šå·²è‡ªåŠ¨å–äº¤é›†å¹¶æŒ‰ RNA åˆ—é¡ºåºå¯¹é½ã€‚")
    st.markdown("</div>", unsafe_allow_html=True)

    if rna.shape[0] < 2 or rna.shape[1] < 4:
        st.error("RNA ç»´åº¦ä¸æ»¡è¶³ï¼šéœ€è¦ genesÃ—samplesï¼Œä¸”æ ·æœ¬æ•°è‡³å°‘ 4ã€‚")
        st.stop()

    genes = rna.index.astype(str).tolist()
    y = labels["Label"].values
    X = MinMaxScaler().fit_transform(rna.T.values)

    st.session_state["cache_artifacts"] = {}
    st.session_state["cache_fig_pngs"] = {}

    all_importances, topk_lists, metrics_runs = [], [], []
    last_shap_z, last_z_test, last_latent_df = None, None, None

    prog = st.progress(0)
    status = st.empty()

    with st.spinner("è®­ç»ƒä¸ SHAP è®¡ç®—ä¸­..."):
        for run_i in range(int(n_runs)):
            seed = int(seed_base + run_i)
            set_seed(seed)
            status.write(f"Run {run_i+1}/{n_runs} | seed={seed}")

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=float(test_size), random_state=seed,
                stratify=y if len(pd.Series(y).unique()) == 2 else None
            )

            X_train_t = torch.tensor(X_train, dtype=torch.float32)
            X_test_t = torch.tensor(X_test, dtype=torch.float32)
            y_train_t = torch.tensor(pd.Series(y_train).astype(float).values, dtype=torch.float32).view(-1, 1)

            vae = VAE(X.shape[1], int(latent_dim))
            mlp = MLP(int(latent_dim))
            optimizer = optim.Adam(list(vae.parameters()) + list(mlp.parameters()), lr=float(lr))

            vae.train(); mlp.train()
            for _ in range(int(n_epochs)):
                optimizer.zero_grad()
                z, mean, log_var = vae(X_train_t)
                y_pred = mlp(z)
                kl = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())
                ce = F.binary_cross_entropy(y_pred, y_train_t, reduction="sum")
                loss = kl + float(ce_weight) * ce
                loss.backward()
                optimizer.step()

            vae.eval(); mlp.eval()
            with torch.no_grad():
                z_test, _, _ = vae(X_test_t)
                y_pred_test = mlp(z_test).cpu().numpy().flatten()

            try:
                auc = roc_auc_score(y_test, y_pred_test)
            except Exception:
                auc = np.nan

            y_hat = (y_pred_test > 0.5).astype(int)
            metrics_runs.append({
                "run": run_i, "seed": seed,
                "AUC": auc,
                "Accuracy": accuracy_score(y_test, y_hat),
                "Precision": precision_score(y_test, y_hat, zero_division=0),
                "Recall": recall_score(y_test, y_hat, zero_division=0),
            })

            with torch.no_grad():
                z_train, _, _ = vae(X_train_t)
            z_train_np = z_train.cpu().numpy()
            z_test_np = z_test.cpu().numpy()

            def mlp_predict(z_numpy):
                z_t = torch.tensor(z_numpy, dtype=torch.float32)
                with torch.no_grad():
                    out = mlp(z_t).cpu().numpy()
                return out.reshape(-1)

            bg_n = int(min(background_n, z_train_np.shape[0]))
            background_z = shap.sample(z_train_np, bg_n)
            explainer = shap.KernelExplainer(mlp_predict, background_z)

            shap_values = explainer.shap_values(z_test_np, nsamples=int(shap_nsamples))
            shap_z = ensure_2d_shap(shap_values, z_test_np)

            W_gene_hidden = vae.fc1.weight.detach().cpu().numpy()
            abs_shap_z = np.mean(np.abs(shap_z), axis=0)
            scale = float(np.sum(abs_shap_z))
            gene_importance = {gene: float(np.mean(np.abs(W_gene_hidden[:, i])) * scale) for i, gene in enumerate(genes)}
            imp_s = pd.Series(gene_importance).reindex(genes)

            all_importances.append(imp_s)
            topk_lists.append(imp_s.sort_values(ascending=False).head(int(top_k)).index.tolist())

            if run_i == int(n_runs) - 1:
                last_shap_z = shap_z
                last_z_test = z_test_np
                abs_latent = np.mean(np.abs(shap_z), axis=0)
                last_latent_df = (
                    pd.DataFrame({"LatentDim": np.arange(len(abs_latent)), "MeanAbsSHAP": abs_latent})
                    .sort_values("MeanAbsSHAP", ascending=False)
                    .reset_index(drop=True)
                )

            prog.progress((run_i + 1) / int(n_runs))

    status.empty(); prog.empty()

    metrics_df = pd.DataFrame(metrics_runs)
    summary_df = metrics_df[["AUC", "Accuracy", "Precision", "Recall"]].agg(["mean", "std"]).T.reset_index()
    summary_df.columns = ["Metric", "Mean", "Std"]

    imp_mat = pd.concat(all_importances, axis=1)
    imp_mat.columns = [f"run_{i}" for i in range(int(n_runs))]
    mean_imp = imp_mat.mean(axis=1)
    std_imp = imp_mat.std(axis=1)
    cv_imp = std_imp / (mean_imp.abs() + 1e-12)

    from collections import Counter
    freq_counter = Counter([g for lst in topk_lists for g in lst])
    freq = pd.Series({g: freq_counter.get(g, 0) / float(n_runs) for g in genes})
    freq_col = f"Top{int(top_k)}_Freq"

    stability_df = pd.DataFrame({
        "Gene": genes,
        "MeanImportance": mean_imp.values,
        "StdImportance": std_imp.values,
        "CV": cv_imp.values,
        freq_col: freq.values,
    }).sort_values([freq_col, "MeanImportance"], ascending=[False, False]).reset_index(drop=True)

    top20_genes = stability_df.sort_values("MeanImportance", ascending=False)["Gene"].head(20).tolist()

    st.session_state["cache_rna"] = rna
    st.session_state["cache_labels"] = labels
    st.session_state["cache_align_info"] = align_info
    st.session_state["cache_label_detect"] = label_detect

    st.session_state["cache_top20_genes"] = top20_genes
    st.session_state["cache_metrics_df"] = metrics_df
    st.session_state["cache_summary_df"] = summary_df
    st.session_state["cache_stability_df"] = stability_df
    st.session_state["cache_latent_df"] = last_latent_df
    st.session_state["cache_last_shap_z"] = last_shap_z
    st.session_state["cache_last_z_test"] = last_z_test

    st.session_state["cache_cached_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    artifact_put_df_csv("model_metrics_all_runs.csv", metrics_df, note="æ¯æ¬¡ run çš„æŒ‡æ ‡")
    artifact_put_df_csv("model_metrics_summary.csv", summary_df, note="æŒ‡æ ‡å‡å€¼Â±æ ‡å‡†å·®")
    artifact_put_df_csv("latent_shap_gene_importance_stability.csv", stability_df, note="åŸºå› ç¨³å®šæ€§ï¼ˆMean/CV/Freqï¼‰")
    if isinstance(last_latent_df, pd.DataFrame):
        artifact_put_df_csv("latent_mean_abs_shap.csv", last_latent_df, note="latent ç»´åº¦ MeanAbsSHAP")

    try:
        if last_shap_z is not None and last_z_test is not None:
            fig1 = plt.figure(figsize=(9.5, 5.5))
            shap.summary_plot(last_shap_z, features=last_z_test, show=False)
            artifact_put_fig_png("shap_summary_dot.png", fig1, note="SHAP summary dot")
            plt.close(fig1)

            fig2 = plt.figure(figsize=(9.5, 5.0))
            shap.summary_plot(last_shap_z, features=last_z_test, plot_type="bar", show=False)
            artifact_put_fig_png("shap_summary_bar.png", fig2, note="SHAP summary bar")
            plt.close(fig2)

        if isinstance(last_latent_df, pd.DataFrame):
            fig3 = plt.figure(figsize=(8.8, 4.2))
            top_lat = last_latent_df.head(20)
            plt.bar(top_lat["LatentDim"].astype(str), top_lat["MeanAbsSHAP"])
            plt.xticks(rotation=45, ha="right")
            plt.title("Top 20 latent dims by MeanAbsSHAP")
            plt.tight_layout()
            artifact_put_fig_png("latent_top20_bar.png", fig3, note="Top20 latent dims")
            plt.close(fig3)
    except Exception:
        pass

    for k in [
        "cache_enrich_go_kegg",
        "cache_de_df",
        "cache_de_groups",
        "cache_cluster_df",
        "cache_cluster_X_scaled",
        "cache_cox_cluster_summary",
    ]:
        st.session_state.pop(k, None)

    st.success("âœ… ä¸»æµç¨‹è¿è¡Œå®Œæˆï¼šç»“æœå·²ç¼“å­˜ï¼ˆåˆ‡æ¢ Tabs / ä¸‹è½½ä¸ä¼šä¸¢å¤±ï¼‰ã€‚")
    # åˆ·æ–°é¡¶éƒ¨å·¥å…·æ çŠ¶æ€
    st.rerun()

# =====================================================
# KPI cards
# =====================================================
if "cache_metrics_df" in st.session_state:
    sdf = st.session_state["cache_summary_df"]
    auc_mean = float(sdf.loc[sdf["Metric"] == "AUC", "Mean"].values[0]) if "AUC" in sdf["Metric"].values else np.nan
    acc_mean = float(sdf.loc[sdf["Metric"] == "Accuracy", "Mean"].values[0]) if "Accuracy" in sdf["Metric"].values else np.nan
    top20 = st.session_state.get("cache_top20_genes", [])

    st.markdown('<div class="card">', unsafe_allow_html=True)
    k1, k2, k3, k4 = st.columns(4)
    with k1:
        st.markdown(f"""<div class="kpi"><div class="label">Runs</div><div class="value">{len(st.session_state["cache_metrics_df"])}</div><div class="hint">é‡å¤è®­ç»ƒæ¬¡æ•°</div></div>""", unsafe_allow_html=True)
    with k2:
        st.markdown(f"""<div class="kpi"><div class="label">AUC (mean)</div><div class="value">{auc_mean:.3f}</div><div class="hint">æµ‹è¯•é›†å¹³å‡ AUC</div></div>""", unsafe_allow_html=True)
    with k3:
        st.markdown(f"""<div class="kpi"><div class="label">Accuracy (mean)</div><div class="value">{acc_mean:.3f}</div><div class="hint">æµ‹è¯•é›†å¹³å‡å‡†ç¡®ç‡</div></div>""", unsafe_allow_html=True)
    with k4:
        st.markdown(f"""<div class="kpi"><div class="label">Top biomarkers</div><div class="value">{len(top20)}</div><div class="hint">ç”¨äºä¸‹æ¸¸åˆ†æ</div></div>""", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

st.divider()

# =====================================================
# Tabs ONLY
# =====================================================
tabs = st.tabs(["â‘  ä¸»æµç¨‹", "â‘¡ ä¸‹è½½ä¸­å¿ƒ", "â‘¢ GO/KEGG", "â‘£ å·®å¼‚åˆ†æ", "â‘¤ èšç±»&ç”Ÿå­˜"])

def _need_run():
    st.info("è¯·å…ˆè¿è¡Œä¸»æµç¨‹ï¼ˆç‚¹å‡»ä¸Šæ–¹ ğŸš€ è¿è¡Œä¸»æµç¨‹ï¼‰ã€‚")

# ---------------- Tab â‘  ä¸»æµç¨‹ ----------------
with tabs[0]:
    st.markdown('<div id="main"></div>', unsafe_allow_html=True)
    st.subheader("â‘  ä¸»æµç¨‹ï¼ˆæ€§èƒ½ / ç¨³å®šæ€§ / SHAPï¼‰")

    st.markdown(
        """
        <div class="card smallMuted">
          å»ºè®®æµç¨‹ï¼šå…ˆè¿è¡Œä¸»æµç¨‹ â†’ çœ‹ Top20 ä¸ç¨³å®šæ€§ â†’ å†åš GO/KEGG æˆ–å·®å¼‚åˆ†æ â†’ æœ€ååšèšç±»ä¸ç”Ÿå­˜éªŒè¯ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

    if "cache_stability_df" not in st.session_state:
        _need_run()
    else:
        metrics_df = st.session_state["cache_metrics_df"]
        summary_df = st.session_state["cache_summary_df"]
        stability_df = st.session_state["cache_stability_df"]
        latent_df = st.session_state.get("cache_latent_df", None)
        top20 = st.session_state["cache_top20_genes"]

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ğŸ“Š æ¨¡å‹æ€§èƒ½ï¼ˆæ¯æ¬¡ runï¼‰")
        st.dataframe(metrics_df, use_container_width=True, height=260)
        st.markdown("#### ğŸ“Š æŒ‡æ ‡æ±‡æ€»ï¼ˆå‡å€¼Â±æ ‡å‡†å·®ï¼‰")
        st.dataframe(summary_df, use_container_width=True, height=210)
        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ğŸ§¬ Top20 å€™é€‰ç”Ÿç‰©æ ‡å¿—ç‰©ï¼ˆMeanImportanceï¼‰")
        st.code("\n".join(top20))
        st.markdown("#### ğŸ“Œ ç¨³å®šæ€§ï¼ˆFrequency / CVï¼‰Top50")
        st.dataframe(stability_df.head(50), use_container_width=True, height=420)
        st.markdown("</div>", unsafe_allow_html=True)

        last_shap_z = st.session_state.get("cache_last_shap_z", None)
        last_z_test = st.session_state.get("cache_last_z_test", None)

        if last_shap_z is not None and last_z_test is not None:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### ğŸ” Latent SHAP Summaryï¼ˆdot / barï¼‰")
            fig1 = plt.figure(figsize=(9.5, 5.5))
            shap.summary_plot(last_shap_z, features=last_z_test, show=False)
            st.pyplot(fig1)
            plt.close(fig1)

            fig2 = plt.figure(figsize=(9.5, 5.0))
            shap.summary_plot(last_shap_z, features=last_z_test, plot_type="bar", show=False)
            st.pyplot(fig2)
            plt.close(fig2)
            st.markdown("</div>", unsafe_allow_html=True)

        if isinstance(latent_df, pd.DataFrame):
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### ğŸ“ˆ Top20 latent ç»´åº¦ï¼ˆMeanAbsSHAPï¼‰")
            st.dataframe(latent_df.head(20), use_container_width=True, height=360)
            st.markdown("</div>", unsafe_allow_html=True)

# ---------------- Tab â‘¡ ä¸‹è½½ä¸­å¿ƒ ----------------
with tabs[1]:
    st.markdown('<div id="download"></div>', unsafe_allow_html=True)
    st.subheader("â‘¡ ä¸‹è½½ä¸­å¿ƒï¼ˆæ–‡ä»¶åˆ—è¡¨ / å•æ–‡ä»¶ / ZIP + REPORTï¼‰")

    if "cache_stability_df" not in st.session_state:
        _need_run()
    else:
        st.markdown(
            """
            <div class="card smallMuted">
              ä¸‹è½½å»ºè®®ï¼šå•æ–‡ä»¶ç”¨äºå¿«é€Ÿå¯¼å‡ºï¼›ZIP ç”¨äºä¸€æ¬¡æ€§æ‰“åŒ…ï¼ˆå« REPORT.md + å›¾ + è¡¨ï¼‰ã€‚
            </div>
            """,
            unsafe_allow_html=True,
        )

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ğŸ“¦ ç»“æœæ–‡ä»¶åˆ—è¡¨ï¼ˆå½“å‰ sessionï¼‰")
        table = artifact_table_df()
        st.dataframe(table, use_container_width=True, height=320)
        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### â¬‡ å•æ–‡ä»¶ä¸‹è½½")
        cols = st.columns(3)
        artifacts = st.session_state.get("cache_artifacts", {})
        if artifacts:
            names = list(artifacts.keys())
            for i, name in enumerate(names):
                meta = artifacts[name]
                with cols[i % 3]:
                    st.download_button(
                        label=f"â¬‡ {name}",
                        data=meta["bytes"],
                        file_name=name,
                        mime=meta["mime"],
                    )
        else:
            st.info("å½“å‰æ²¡æœ‰å¯ä¸‹è½½æ–‡ä»¶ã€‚")
        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ğŸ§¾ ZIP æ‰“åŒ…ï¼ˆå« REPORT.mdï¼‰")
        ts = now_stamp()
        zip_name = f"results_{ts}.zip"
        zip_bytes = build_results_zip(ts)
        st.download_button("â¬‡ ä¸‹è½½ ZIPï¼ˆresults_*.zipï¼‰", zip_bytes, zip_name, mime="application/zip")
        with st.expander("é¢„è§ˆ REPORT.mdï¼ˆä¼šåŒ…å«åœ¨ ZIPï¼‰", expanded=False):
            st.markdown(build_report_md())
        st.markdown("</div>", unsafe_allow_html=True)

# ---------------- Tab â‘¢ GO/KEGG ----------------
with tabs[2]:
    st.markdown('<div id="enrich"></div>', unsafe_allow_html=True)
    st.subheader("â‘¢ GO / KEGG å¯Œé›†åˆ†æï¼ˆTop20ï¼‰")

    if "cache_top20_genes" not in st.session_state:
        _need_run()
    else:
        top_genes = st.session_state["cache_top20_genes"]

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### è¾“å…¥åŸºå› ï¼ˆTop20ï¼‰")
        st.code("\n".join(top_genes))
        org = st.selectbox("ç‰©ç§ï¼ˆEnrichr organismï¼‰", ["Human", "Mouse"], index=0)
        st.markdown('<div class="smallMuted">ä¾èµ–ï¼šgseapy + ç½‘ç»œè®¿é—® Enrichr</div>', unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

        if not GSEAPY_OK:
            st.warning("æœªå®‰è£… gseapyï¼Œæ— æ³•åš GO/KEGGï¼špip install gseapy")
        else:
            if st.button("ğŸ§ª è¿è¡Œ GO/KEGGï¼ˆEnrichrï¼‰", type="primary"):
                with st.spinner("å¯Œé›†åˆ†æè¿è¡Œä¸­ï¼ˆéœ€è¦è”ç½‘è®¿é—® Enrichrï¼‰..."):
                    try:
                        res_dict = run_enrichr(top_genes, organism=org)
                        st.session_state["cache_enrich_go_kegg"] = res_dict
                        for lib, df in res_dict.items():
                            artifact_put_df_csv(f"enrichr_{lib}.csv", df, note=f"Enrichr: {lib}")
                        st.success("å¯Œé›†å®Œæˆ âœ…")
                    except Exception as e:
                        st.error(f"å¯Œé›†å¤±è´¥ï¼š{e}")

            if "cache_enrich_go_kegg" in st.session_state:
                res_dict = st.session_state["cache_enrich_go_kegg"]
                for lib, df in res_dict.items():
                    st.markdown('<div class="card">', unsafe_allow_html=True)
                    st.markdown(f"#### {lib}")
                    st.dataframe(df.head(20), use_container_width=True, height=360)
                    st.download_button(
                        f"â¬‡ ä¸‹è½½ {lib}",
                        df.to_csv(index=False).encode("utf-8"),
                        f"enrichr_{lib}.csv",
                        mime="text/csv",
                    )
                    st.markdown("</div>", unsafe_allow_html=True)

# ---------------- Tab â‘£ å·®å¼‚åˆ†æ ----------------
with tabs[3]:
    st.markdown('<div id="de"></div>', unsafe_allow_html=True)
    st.subheader("â‘£ å·®å¼‚åˆ†æï¼ˆlabels ä¸¤ç»„ï¼ŒTop20ï¼‰")

    if "cache_rna" not in st.session_state or "cache_labels" not in st.session_state:
        _need_run()
    else:
        rna = st.session_state["cache_rna"]
        labels = st.session_state["cache_labels"]
        top_genes = st.session_state["cache_top20_genes"]

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### ä¾èµ–æ£€æŸ¥")
        st.write({"scipy": SCIPY_OK, "statsmodels": STATSMODELS_OK})
        st.markdown("</div>", unsafe_allow_html=True)

        if not (SCIPY_OK and STATSMODELS_OK):
            st.warning("å·®å¼‚åˆ†æéœ€è¦ï¼špip install scipy statsmodels")
        else:
            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### è¿è¡Œä¸ç»“æœ")
            if st.button("ğŸ§¬ è¿è¡Œ Top20 å·®å¼‚åˆ†æï¼ˆt-test + FDRï¼‰", type="primary"):
                with st.spinner("å·®å¼‚åˆ†æè®¡ç®—ä¸­..."):
                    try:
                        de_df, groups = compute_de_top_genes(rna, labels, top_genes)
                        st.session_state["cache_de_df"] = de_df
                        st.session_state["cache_de_groups"] = groups
                        artifact_put_df_csv("top20_differential_expression.csv", de_df, note="Top20 DE (t-test+FDR)")
                        st.success("å·®å¼‚åˆ†æå®Œæˆ âœ…")
                    except Exception as e:
                        st.error(f"å·®å¼‚åˆ†æå¤±è´¥ï¼š{e}")
            st.markdown("</div>", unsafe_allow_html=True)

        if "cache_de_df" in st.session_state:
            de_df = st.session_state["cache_de_df"]

            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### å·®å¼‚ç»“æœï¼ˆTop20ï¼‰")
            st.dataframe(de_df, use_container_width=True, height=360)
            st.download_button(
                "â¬‡ ä¸‹è½½å·®å¼‚ç»“æœ",
                de_df.to_csv(index=False).encode("utf-8"),
                "top20_differential_expression.csv",
                mime="text/csv",
            )
            st.markdown("</div>", unsafe_allow_html=True)

            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### ç«å±±å›¾ï¼ˆTop20ï¼‰")
            figv = plt.figure(figsize=(7.8, 4.6))
            x = de_df["log2FC"].values
            yv = -np.log10(de_df["p_value"].values + 1e-300)
            plt.scatter(x, yv)
            for _, row in de_df.iterrows():
                plt.text(row["log2FC"], -np.log10(row["p_value"] + 1e-300), row["Gene"], fontsize=8)
            plt.xlabel("log2FC")
            plt.ylabel("-log10(p)")
            plt.title("Volcano (Top20)")
            plt.tight_layout()
            st.pyplot(figv)
            artifact_put_fig_png("de_volcano_top20.png", figv, note="Volcano plot (Top20)")
            plt.close(figv)
            st.markdown("</div>", unsafe_allow_html=True)

# ---------------- Tab â‘¤ èšç±» & ç”Ÿå­˜ ----------------
with tabs[4]:
    st.markdown('<div id="survival"></div>', unsafe_allow_html=True)
    st.subheader("â‘¤ èšç±»ï¼ˆTop20ï¼‰+ ç”Ÿå­˜ï¼ˆKM/Coxï¼‰")

    if "cache_rna" not in st.session_state or "cache_top20_genes" not in st.session_state:
        _need_run()
    else:
        rna = st.session_state["cache_rna"]
        top_genes = st.session_state["cache_top20_genes"]

        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("#### èšç±»è¾“å…¥ï¼ˆTop20ï¼‰")
        st.code("\n".join(top_genes))
        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown('<div class="card">', unsafe_allow_html=True)
        if st.button("ğŸ§© è¿è¡Œèšç±»ï¼ˆTop20 åŸºå› è¡¨è¾¾ï¼‰", type="primary"):
            with st.spinner("èšç±»ä¸­..."):
                try:
                    cluster_df, X_scaled_df = cluster_samples_by_top_genes(
                        rna=rna, top_genes=top_genes, n_clusters=int(cluster_k), seed=int(seed_base)
                    )
                    st.session_state["cache_cluster_df"] = cluster_df
                    st.session_state["cache_cluster_X_scaled"] = X_scaled_df
                    artifact_put_df_csv("top20_cluster_labels.csv", cluster_df, note="KMeans clusters by Top20")
                    st.success("èšç±»å®Œæˆ âœ…")
                except Exception as e:
                    st.error(f"èšç±»å¤±è´¥ï¼š{e}")
        st.markdown("</div>", unsafe_allow_html=True)

        if "cache_cluster_df" in st.session_state:
            cluster_df = st.session_state["cache_cluster_df"]
            X_scaled_df = st.session_state.get("cache_cluster_X_scaled", None)

            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### èšç±»ç»“æœï¼ˆSample â†’ Clusterï¼‰")
            st.dataframe(cluster_df.head(100), use_container_width=True, height=340)
            st.download_button(
                "â¬‡ ä¸‹è½½èšç±»ç»“æœ",
                cluster_df.to_csv(index=False).encode("utf-8"),
                "top20_cluster_labels.csv",
                mime="text/csv",
            )
            st.markdown("</div>", unsafe_allow_html=True)

            if X_scaled_df is not None:
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.markdown("#### çƒ­å›¾ï¼ˆz-scoreï¼ŒæŒ‰ Cluster æ’åºï¼‰")
                df_plot = X_scaled_df.copy()
                df_plot["Cluster"] = cluster_df.set_index("Sample").loc[df_plot.index]["Cluster"].values
                df_plot = df_plot.sort_values("Cluster")
                mat = df_plot.drop(columns=["Cluster"]).values

                fig_h = plt.figure(figsize=(10.0, 5.0))
                plt.imshow(mat, aspect="auto")
                plt.colorbar(label="z-score")
                plt.yticks([])
                plt.xticks(range(df_plot.shape[1] - 1), df_plot.drop(columns=["Cluster"]).columns, rotation=90, fontsize=7)
                plt.title("Top20 genes (z-score) sorted by Cluster")
                plt.tight_layout()
                st.pyplot(fig_h)
                artifact_put_fig_png("cluster_heatmap_top20.png", fig_h, note="Heatmap by cluster")
                plt.close(fig_h)
                st.markdown("</div>", unsafe_allow_html=True)

            st.markdown('<div class="card">', unsafe_allow_html=True)
            st.markdown("#### ç”Ÿå­˜åˆ†æï¼ˆæŒ‰ Cluster åˆ†ç»„ï¼‰")
            if not LIFELINES_OK:
                st.warning("æœªå®‰è£… lifelinesï¼špip install lifelines")
            else:
                surv_df_source = read_csv_cached(surv_file) if surv_file is not None else st.session_state.get("cache_demo_surv_raw", None)
                if surv_df_source is None:
                    st.info("æœªæä¾›ç”Ÿå­˜æ•°æ®ï¼ˆä¸Šä¼ æˆ–ç¤ºä¾‹ sur.csvï¼‰ï¼Œè·³è¿‡ KM/Coxã€‚")
                else:
                    surv = clean_columns(surv_df_source.copy())
                    if "Sample" not in surv.columns:
                        surv_cols = {_norm(c): c for c in surv.columns}
                        for a in ["sample", "sampleid", "id", "subject", "patient"]:
                            if _norm(a) in surv_cols:
                                surv = surv.rename(columns={surv_cols[_norm(a)]: "Sample"})
                                break

                    if "Sample" not in surv.columns or "Time" not in surv.columns or "Event" not in surv.columns:
                        st.error("ç”Ÿå­˜æ•°æ®å¿…é¡»åŒ…å«åˆ—ï¼šSample, Time, Event")
                    else:
                        surv["Sample"] = surv["Sample"].astype(str).str.strip()
                        surv = surv.set_index("Sample")

                        cl = cluster_df.copy()
                        cl["Sample"] = cl["Sample"].astype(str).str.strip()
                        cl = cl.set_index("Sample")

                        common = sorted(list(set(cl.index).intersection(set(surv.index))))
                        if len(common) < 10:
                            st.error("ç”Ÿå­˜æ•°æ®ä¸èšç±»æ ·æœ¬äº¤é›†å¤ªå°‘ï¼ˆ<10ï¼‰ï¼Œæ— æ³•ç”Ÿå­˜åˆ†æã€‚")
                        else:
                            surv_aligned = surv.loc[common].copy()
                            surv_aligned["Cluster"] = cl.loc[common]["Cluster"].astype(int).values
                            surv_aligned["Time"] = pd.to_numeric(surv_aligned["Time"], errors="coerce")
                            surv_aligned["Event"] = pd.to_numeric(surv_aligned["Event"], errors="coerce")
                            surv_aligned = surv_aligned.dropna(subset=["Time", "Event", "Cluster"])

                            fig_km, p_lr = km_plot_by_group(surv_aligned, group_col="Cluster")
                            st.pyplot(fig_km)
                            artifact_put_fig_png("survival_km_by_cluster.png", fig_km, note="KM curves by cluster")
                            plt.close(fig_km)
                            if p_lr is not None:
                                st.write({"Log-rank p-value (2 groups)": p_lr})

                            st.markdown("##### Coxï¼ˆCluster ä½œä¸ºåå˜é‡ï¼‰")
                            df_cox = surv_aligned[["Time", "Event", "Cluster"]].copy().reset_index(drop=True)
                            df_cox = pd.get_dummies(df_cox, columns=["Cluster"], drop_first=True)

                            df_train, df_test = train_test_split(df_cox, test_size=float(test_size), random_state=int(seed_base))
                            cph = CoxPHFitter(penalizer=float(cox_penalizer))
                            cph.fit(df_train, duration_col="Time", event_col="Event")

                            risk = cph.predict_partial_hazard(df_test)
                            c_index = concordance_index(df_test["Time"], -risk.values, df_test["Event"])
                            st.write({"C-index": float(c_index)})

                            cox_sum = cph.summary.reset_index()
                            st.session_state["cache_cox_cluster_summary"] = cox_sum
                            artifact_put_df_csv("cox_cluster_summary.csv", cox_sum, note="Cox summary (Cluster)")
                            st.dataframe(cox_sum, use_container_width=True, height=360)
                            st.download_button(
                                "â¬‡ ä¸‹è½½ Cox summaryï¼ˆClusterï¼‰",
                                cox_sum.to_csv(index=False).encode("utf-8"),
                                "cox_cluster_summary.csv",
                                mime="text/csv",
                            )
            st.markdown("</div>", unsafe_allow_html=True)

st.divider()
st.caption(
    "ä¾èµ–æç¤ºï¼šåŸºç¡€åŠŸèƒ½éœ€ streamlit/pandas/numpy/torch/scikit-learn/shap/matplotlibï¼›"
    "å·®å¼‚åˆ†æéœ€ scipy + statsmodelsï¼›"
    "GO/KEGGï¼ˆEnrichrï¼‰éœ€ gseapy ä¸”éœ€è¦ç½‘ç»œï¼›"
    "ç”Ÿå­˜åˆ†æéœ€ lifelinesã€‚"
)
